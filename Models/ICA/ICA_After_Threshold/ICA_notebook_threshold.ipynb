{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the feature matrix and labels \n",
    "feature_matrix = np.load('D:/NLP Project/ICA/feature_matrix.npy')\n",
    "class_labels = np.load('D:/NLP Project/ICA/class_lables.npy')\n",
    "indices = np.arange(len(feature_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_df = pd.read_csv('D:/NLP Project/ICA/edge_list.csv')\n",
    "#loading the edgelist and constructing the url graph\n",
    "g = nx.from_pandas_edgelist(graph_df,'url1','url2',edge_attr='edge_weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickling weighted URL graph.\n",
    "#pickle.dump(g, open('D:/NLP Project/ICA/url_graph_pickle.txt','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g = pickle.load(open('D:/NLP Project/ICA/url_graph_pickle.txt',mode= 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Nodes with single neighbors won't be considered for thresholding - dangling nodes. (Will avoid index error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17601"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes = list(g.nodes)\n",
    "len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_labels = class_labels #making a copy of class labels for updations during iteration\n",
    "# Contains true labels of all documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3]), array([4440, 4236, 5143, 3782], dtype=int64))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(class_labels,return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Graph with 17601 nodes and 45259074 edges'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.info(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url1</th>\n",
       "      <th>url2</th>\n",
       "      <th>edge_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5361</td>\n",
       "      <td>5362</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5361</td>\n",
       "      <td>5363</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5361</td>\n",
       "      <td>5364</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5361</td>\n",
       "      <td>5365</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5361</td>\n",
       "      <td>5366</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   url1  url2  edge_weight\n",
       "0  5361  5362            7\n",
       "1  5361  5363            8\n",
       "2  5361  5364            7\n",
       "3  5361  5365            6\n",
       "4  5361  5366            6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90518148"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(graph_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     62866404\n",
      "2     17974752\n",
      "3      4942704\n",
      "4      2163040\n",
      "5      1145002\n",
      "6       676434\n",
      "7       365660\n",
      "8       182488\n",
      "9        87832\n",
      "10       42580\n",
      "Name: edge_weight, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "edge_weight_counts = graph_df['edge_weight'].value_counts()\n",
    "print(edge_weight_counts.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7738"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.degree[5361]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5361: 7738,\n",
       " 5362: 7359,\n",
       " 5363: 6370,\n",
       " 5364: 6867,\n",
       " 5365: 6585,\n",
       " 5366: 6427,\n",
       " 5367: 8021,\n",
       " 5368: 7431,\n",
       " 5369: 6041,\n",
       " 5370: 10597,\n",
       " 5371: 8173,\n",
       " 5372: 9535,\n",
       " 5373: 5882,\n",
       " 5790: 7060,\n",
       " 5791: 4801,\n",
       " 5792: 6735,\n",
       " 5793: 7524,\n",
       " 5794: 6307,\n",
       " 5795: 9270,\n",
       " 5796: 6818,\n",
       " 5797: 5563,\n",
       " 5798: 8674,\n",
       " 5799: 7191,\n",
       " 5800: 7134,\n",
       " 5801: 7198,\n",
       " 5802: 5231,\n",
       " 5803: 8013,\n",
       " 5804: 5899,\n",
       " 5805: 6400,\n",
       " 5806: 7544,\n",
       " 5807: 7624,\n",
       " 6793: 7654,\n",
       " 6794: 4839,\n",
       " 6795: 8446,\n",
       " 6796: 5787,\n",
       " 6798: 7733,\n",
       " 6799: 6212,\n",
       " 6800: 4397,\n",
       " 6801: 5433,\n",
       " 6802: 7229,\n",
       " 6803: 5624,\n",
       " 6804: 7716,\n",
       " 6805: 8371,\n",
       " 6806: 4923,\n",
       " 6807: 5218,\n",
       " 6808: 8343,\n",
       " 6809: 8029,\n",
       " 6810: 9925,\n",
       " 6811: 6409,\n",
       " 6812: 6485,\n",
       " 6813: 7564,\n",
       " 6814: 8849,\n",
       " 6815: 7383,\n",
       " 6816: 6793,\n",
       " 6817: 7243,\n",
       " 6818: 8914,\n",
       " 6819: 8135,\n",
       " 6820: 6746,\n",
       " 6821: 6365,\n",
       " 6822: 8373,\n",
       " 6823: 7130,\n",
       " 6824: 5936,\n",
       " 6825: 6952,\n",
       " 6826: 6211,\n",
       " 6827: 7030,\n",
       " 6828: 7679,\n",
       " 6829: 6814,\n",
       " 6830: 5529,\n",
       " 6831: 6968,\n",
       " 7133: 5478,\n",
       " 7134: 7015,\n",
       " 7135: 7332,\n",
       " 7136: 7430,\n",
       " 7137: 7300,\n",
       " 7138: 7131,\n",
       " 7139: 8585,\n",
       " 7140: 6920,\n",
       " 7141: 7132,\n",
       " 7142: 7206,\n",
       " 7143: 8043,\n",
       " 7144: 6662,\n",
       " 7145: 5666,\n",
       " 7146: 5266,\n",
       " 7147: 9887,\n",
       " 7148: 7608,\n",
       " 7149: 5915,\n",
       " 7150: 9035,\n",
       " 7151: 8361,\n",
       " 7152: 10029,\n",
       " 7153: 5960,\n",
       " 7154: 4795,\n",
       " 7155: 6608,\n",
       " 7156: 6559,\n",
       " 7157: 5807,\n",
       " 7158: 8636,\n",
       " 7159: 7355,\n",
       " 7160: 5996,\n",
       " 7161: 7465,\n",
       " 7162: 5931,\n",
       " 7163: 5836,\n",
       " 7164: 7179,\n",
       " 7165: 8315,\n",
       " 7166: 7025,\n",
       " 7167: 6883,\n",
       " 7995: 8566,\n",
       " 7997: 7920,\n",
       " 7998: 7753,\n",
       " 7999: 6110,\n",
       " 8000: 7102,\n",
       " 8001: 7714,\n",
       " 8002: 7559,\n",
       " 8003: 7539,\n",
       " 8004: 8569,\n",
       " 8005: 7916,\n",
       " 8006: 11726,\n",
       " 8007: 6339,\n",
       " 8008: 5488,\n",
       " 8009: 9258,\n",
       " 8010: 5103,\n",
       " 8011: 8013,\n",
       " 8012: 6950,\n",
       " 8013: 8492,\n",
       " 8014: 6348,\n",
       " 8015: 9645,\n",
       " 8016: 7280,\n",
       " 8017: 10058,\n",
       " 8018: 8540,\n",
       " 8019: 7010,\n",
       " 5374: 10971,\n",
       " 5375: 9693,\n",
       " 5376: 9916,\n",
       " 5377: 9397,\n",
       " 5379: 12328,\n",
       " 5380: 11395,\n",
       " 5383: 9947,\n",
       " 5384: 10367,\n",
       " 5385: 6620,\n",
       " 5387: 8069,\n",
       " 5391: 11549,\n",
       " 5394: 9585,\n",
       " 5808: 7565,\n",
       " 5809: 8763,\n",
       " 5810: 6964,\n",
       " 5811: 8391,\n",
       " 5812: 9589,\n",
       " 5813: 9972,\n",
       " 5814: 7873,\n",
       " 5815: 9066,\n",
       " 5816: 7454,\n",
       " 5817: 8020,\n",
       " 5818: 10403,\n",
       " 5819: 7783,\n",
       " 5820: 9487,\n",
       " 5821: 10519,\n",
       " 5822: 7710,\n",
       " 5823: 9254,\n",
       " 5824: 11420,\n",
       " 5825: 8236,\n",
       " 5826: 8500,\n",
       " 5827: 6465,\n",
       " 5828: 8899,\n",
       " 5829: 6899,\n",
       " 5830: 7774,\n",
       " 5831: 9294,\n",
       " 5832: 9830,\n",
       " 5833: 9420,\n",
       " 5834: 8853,\n",
       " 5835: 8853,\n",
       " 5836: 8474,\n",
       " 5837: 9983,\n",
       " 5838: 7820,\n",
       " 5839: 7865,\n",
       " 5840: 9717,\n",
       " 5841: 9913,\n",
       " 5842: 7072,\n",
       " 5843: 9738,\n",
       " 5844: 9319,\n",
       " 5845: 6433,\n",
       " 5846: 7506,\n",
       " 5847: 11307,\n",
       " 5848: 7761,\n",
       " 5849: 10264,\n",
       " 5850: 5617,\n",
       " 5851: 7312,\n",
       " 5852: 8624,\n",
       " 5853: 8155,\n",
       " 5854: 4266,\n",
       " 5855: 5975,\n",
       " 5856: 9654,\n",
       " 5858: 5413,\n",
       " 5861: 8191,\n",
       " 5863: 9564,\n",
       " 5864: 9801,\n",
       " 5865: 8272,\n",
       " 5866: 9216,\n",
       " 5867: 9482,\n",
       " 5868: 9002,\n",
       " 5869: 7832,\n",
       " 5870: 11751,\n",
       " 5871: 8202,\n",
       " 5873: 8896,\n",
       " 5874: 10668,\n",
       " 5875: 8435,\n",
       " 5876: 9456,\n",
       " 5878: 7766,\n",
       " 5879: 9492,\n",
       " 5881: 8903,\n",
       " 5883: 5907,\n",
       " 5884: 7363,\n",
       " 5885: 9424,\n",
       " 5887: 9587,\n",
       " 5888: 8576,\n",
       " 5889: 9376,\n",
       " 5890: 10075,\n",
       " 5893: 8975,\n",
       " 5894: 9839,\n",
       " 5895: 10551,\n",
       " 5896: 6975,\n",
       " 5897: 7036,\n",
       " 5898: 12100,\n",
       " 5900: 9988,\n",
       " 5901: 9379,\n",
       " 5902: 8934,\n",
       " 5903: 8023,\n",
       " 5905: 6300,\n",
       " 5906: 8805,\n",
       " 5908: 8772,\n",
       " 5910: 5789,\n",
       " 5913: 7698,\n",
       " 5914: 9533,\n",
       " 5915: 10796,\n",
       " 5916: 8285,\n",
       " 5917: 7007,\n",
       " 5918: 8163,\n",
       " 5924: 9640,\n",
       " 5925: 9060,\n",
       " 5926: 7661,\n",
       " 5928: 7401,\n",
       " 5929: 10533,\n",
       " 5930: 5113,\n",
       " 5931: 6405,\n",
       " 5934: 9791,\n",
       " 5936: 8872,\n",
       " 5939: 11671,\n",
       " 5942: 7372,\n",
       " 5945: 10749,\n",
       " 5946: 8460,\n",
       " 5947: 9205,\n",
       " 5949: 9683,\n",
       " 5950: 8801,\n",
       " 5953: 8733,\n",
       " 5954: 7093,\n",
       " 5955: 6566,\n",
       " 5957: 7494,\n",
       " 5958: 7410,\n",
       " 5959: 9469,\n",
       " 5961: 9885,\n",
       " 5962: 8258,\n",
       " 5963: 5389,\n",
       " 5964: 7003,\n",
       " 5965: 9081,\n",
       " 5968: 7524,\n",
       " 5969: 6291,\n",
       " 5970: 9248,\n",
       " 5971: 8920,\n",
       " 5972: 7832,\n",
       " 5974: 9583,\n",
       " 5975: 8871,\n",
       " 5977: 7260,\n",
       " 5978: 10206,\n",
       " 5979: 7305,\n",
       " 5980: 7761,\n",
       " 5982: 7431,\n",
       " 5983: 8642,\n",
       " 5984: 7876,\n",
       " 5985: 10758,\n",
       " 5989: 9333,\n",
       " 5990: 7958,\n",
       " 5991: 6349,\n",
       " 5992: 9387,\n",
       " 5993: 8994,\n",
       " 5994: 9972,\n",
       " 5996: 4263,\n",
       " 5997: 9525,\n",
       " 5998: 10615,\n",
       " 6002: 10134,\n",
       " 6003: 8024,\n",
       " 6004: 8958,\n",
       " 6005: 8761,\n",
       " 6007: 6972,\n",
       " 6008: 7149,\n",
       " 6009: 6315,\n",
       " 6012: 8611,\n",
       " 6014: 5449,\n",
       " 6015: 6160,\n",
       " 6016: 7442,\n",
       " 6017: 7958,\n",
       " 6021: 11445,\n",
       " 6022: 6650,\n",
       " 6024: 7583,\n",
       " 6025: 7490,\n",
       " 6026: 9205,\n",
       " 6027: 7886,\n",
       " 6028: 8250,\n",
       " 6029: 7067,\n",
       " 6030: 8154,\n",
       " 6033: 9622,\n",
       " 6034: 10303,\n",
       " 6037: 6738,\n",
       " 6038: 5761,\n",
       " 6039: 9054,\n",
       " 6041: 9982,\n",
       " 6042: 8649,\n",
       " 6043: 10658,\n",
       " 6044: 9018,\n",
       " 6045: 6394,\n",
       " 6046: 10271,\n",
       " 6047: 9950,\n",
       " 6049: 10950,\n",
       " 6051: 5382,\n",
       " 6052: 6079,\n",
       " 6053: 7497,\n",
       " 6054: 5276,\n",
       " 6055: 9450,\n",
       " 6057: 7739,\n",
       " 6058: 9739,\n",
       " 6059: 8809,\n",
       " 6060: 6124,\n",
       " 6061: 7104,\n",
       " 6063: 10311,\n",
       " 6064: 10082,\n",
       " 6065: 8200,\n",
       " 6066: 8664,\n",
       " 6067: 8984,\n",
       " 6068: 7628,\n",
       " 6070: 7129,\n",
       " 6072: 6567,\n",
       " 6073: 6557,\n",
       " 6074: 7548,\n",
       " 6075: 8364,\n",
       " 6077: 8550,\n",
       " 6078: 8245,\n",
       " 6079: 6086,\n",
       " 6080: 6086,\n",
       " 6081: 9439,\n",
       " 6082: 7811,\n",
       " 6083: 8306,\n",
       " 6086: 8287,\n",
       " 6087: 9481,\n",
       " 6088: 8472,\n",
       " 6089: 7852,\n",
       " 6090: 10020,\n",
       " 6091: 6690,\n",
       " 6093: 8816,\n",
       " 6094: 10681,\n",
       " 6095: 6450,\n",
       " 6096: 7452,\n",
       " 6097: 8502,\n",
       " 6098: 7257,\n",
       " 6099: 6562,\n",
       " 6100: 10344,\n",
       " 6101: 8988,\n",
       " 6102: 9399,\n",
       " 6103: 11350,\n",
       " 6104: 8256,\n",
       " 6105: 8769,\n",
       " 6106: 8741,\n",
       " 6108: 7293,\n",
       " 6109: 7986,\n",
       " 6111: 7214,\n",
       " 6112: 10112,\n",
       " 6113: 7108,\n",
       " 6115: 6538,\n",
       " 6119: 9688,\n",
       " 6120: 8191,\n",
       " 6122: 9229,\n",
       " 6123: 10271,\n",
       " 6124: 7623,\n",
       " 6126: 9626,\n",
       " 6127: 10629,\n",
       " 6128: 10051,\n",
       " 6130: 6335,\n",
       " 6131: 8709,\n",
       " 6132: 7514,\n",
       " 6134: 10088,\n",
       " 6136: 5844,\n",
       " 6137: 6531,\n",
       " 6138: 4884,\n",
       " 6139: 6534,\n",
       " 6142: 10255,\n",
       " 6143: 9354,\n",
       " 6144: 11179,\n",
       " 6145: 9228,\n",
       " 6146: 7844,\n",
       " 6147: 9259,\n",
       " 6148: 11797,\n",
       " 6150: 6192,\n",
       " 6152: 7599,\n",
       " 6153: 8339,\n",
       " 6154: 9538,\n",
       " 6155: 6379,\n",
       " 6157: 9666,\n",
       " 6158: 9878,\n",
       " 6159: 8032,\n",
       " 6164: 7333,\n",
       " 6165: 5024,\n",
       " 6167: 9924,\n",
       " 6168: 8113,\n",
       " 6170: 6370,\n",
       " 6171: 7199,\n",
       " 6173: 6108,\n",
       " 6174: 8969,\n",
       " 6175: 8332,\n",
       " 6176: 8931,\n",
       " 6178: 7721,\n",
       " 6180: 9236,\n",
       " 6181: 6210,\n",
       " 6182: 6328,\n",
       " 6183: 8090,\n",
       " 6184: 10127,\n",
       " 6185: 8811,\n",
       " 6187: 8479,\n",
       " 6190: 8039,\n",
       " 6192: 7616,\n",
       " 6193: 9486,\n",
       " 6195: 7286,\n",
       " 6196: 7113,\n",
       " 6197: 10203,\n",
       " 6198: 7531,\n",
       " 6199: 7338,\n",
       " 6200: 5287,\n",
       " 6202: 4493,\n",
       " 6203: 5411,\n",
       " 6204: 8839,\n",
       " 6205: 7507,\n",
       " 6206: 9344,\n",
       " 6207: 7514,\n",
       " 6210: 10553,\n",
       " 6211: 6807,\n",
       " 6212: 9389,\n",
       " 6213: 8216,\n",
       " 6216: 6217,\n",
       " 6217: 8113,\n",
       " 6832: 7630,\n",
       " 6833: 9087,\n",
       " 6834: 7161,\n",
       " 6835: 6696,\n",
       " 6837: 9088,\n",
       " 6838: 9182,\n",
       " 6841: 10858,\n",
       " 6842: 7649,\n",
       " 6844: 9077,\n",
       " 6846: 8577,\n",
       " 6847: 9158,\n",
       " 6848: 10294,\n",
       " 6850: 9928,\n",
       " 6855: 9635,\n",
       " 6857: 7372,\n",
       " 6858: 7972,\n",
       " 6862: 9511,\n",
       " 6863: 8301,\n",
       " 6865: 9676,\n",
       " 6869: 9115,\n",
       " 6870: 5604,\n",
       " 6871: 7943,\n",
       " 6872: 6403,\n",
       " 6877: 8933,\n",
       " 6878: 9964,\n",
       " 6879: 7772,\n",
       " 6881: 7720,\n",
       " 6882: 7562,\n",
       " 6883: 7244,\n",
       " 6884: 9179,\n",
       " 6890: 9601,\n",
       " 6891: 8177,\n",
       " 6894: 9516,\n",
       " 6895: 10638,\n",
       " 6896: 8795,\n",
       " 6898: 7422,\n",
       " 6900: 12200,\n",
       " 6904: 6991,\n",
       " 6905: 8018,\n",
       " 6906: 7775,\n",
       " 6908: 8155,\n",
       " 6909: 7576,\n",
       " 6911: 11501,\n",
       " 6915: 8712,\n",
       " 6916: 8767,\n",
       " 6918: 7917,\n",
       " 6919: 8121,\n",
       " 6920: 7526,\n",
       " 6922: 9083,\n",
       " 6923: 7112,\n",
       " 6924: 7878,\n",
       " 6925: 9929,\n",
       " 6926: 6432,\n",
       " 6927: 7407,\n",
       " 6928: 9805,\n",
       " 6932: 6239,\n",
       " 6934: 10224,\n",
       " 6936: 10480,\n",
       " 6937: 8633,\n",
       " 6938: 8465,\n",
       " 6939: 11363,\n",
       " 6942: 5431,\n",
       " 6945: 7442,\n",
       " 6946: 9599,\n",
       " 6949: 10088,\n",
       " 6952: 6330,\n",
       " 7168: 7850,\n",
       " 7169: 7308,\n",
       " 7170: 8886,\n",
       " 7171: 8811,\n",
       " 7172: 8446,\n",
       " 7173: 9972,\n",
       " 7174: 8539,\n",
       " 7175: 8474,\n",
       " 7176: 8541,\n",
       " 7177: 9493,\n",
       " 7178: 8975,\n",
       " 7179: 6230,\n",
       " 7180: 7582,\n",
       " 7181: 7867,\n",
       " 7182: 8963,\n",
       " 7183: 8035,\n",
       " 7184: 8774,\n",
       " 7185: 9310,\n",
       " 7186: 5663,\n",
       " 7187: 7049,\n",
       " 7188: 8693,\n",
       " 7189: 7658,\n",
       " 7190: 7348,\n",
       " 7191: 8150,\n",
       " 7192: 7134,\n",
       " 7193: 9028,\n",
       " 7194: 9623,\n",
       " 7195: 5927,\n",
       " 7196: 7734,\n",
       " 7197: 7712,\n",
       " 7198: 8573,\n",
       " 7199: 6265,\n",
       " 7200: 7891,\n",
       " 7201: 9278,\n",
       " 7202: 6200,\n",
       " 7203: 6273,\n",
       " 7204: 7377,\n",
       " 7205: 6778,\n",
       " 7206: 7913,\n",
       " 7207: 6832,\n",
       " 7208: 8852,\n",
       " 7209: 8367,\n",
       " 7210: 9200,\n",
       " 7211: 9894,\n",
       " 7212: 8787,\n",
       " 7213: 8568,\n",
       " 7214: 9364,\n",
       " 7215: 7912,\n",
       " 7216: 9023,\n",
       " 7217: 8953,\n",
       " 7218: 10868,\n",
       " 7219: 5670,\n",
       " 7220: 8348,\n",
       " 7221: 7739,\n",
       " 7222: 4627,\n",
       " 7223: 6658,\n",
       " 7224: 6001,\n",
       " 7225: 9817,\n",
       " 7226: 7988,\n",
       " 7227: 7108,\n",
       " 7228: 7770,\n",
       " 7229: 8031,\n",
       " 7230: 6361,\n",
       " 7231: 9347,\n",
       " 7232: 7995,\n",
       " 7233: 8645,\n",
       " 7234: 10395,\n",
       " 7235: 7064,\n",
       " 7236: 8078,\n",
       " 7237: 10236,\n",
       " 7238: 8668,\n",
       " 7239: 8667,\n",
       " 7240: 7255,\n",
       " 7241: 7716,\n",
       " 7243: 9929,\n",
       " 7244: 9301,\n",
       " 7245: 8461,\n",
       " 7246: 7392,\n",
       " 7247: 7415,\n",
       " 7248: 6695,\n",
       " 7249: 7058,\n",
       " 7250: 7718,\n",
       " 7251: 8039,\n",
       " 7252: 6443,\n",
       " 7253: 9096,\n",
       " 7254: 9166,\n",
       " 7255: 7863,\n",
       " 7256: 8194,\n",
       " 7257: 7624,\n",
       " 7258: 7180,\n",
       " 7259: 10628,\n",
       " 7260: 7532,\n",
       " 7261: 6126,\n",
       " 7262: 7962,\n",
       " 7263: 6814,\n",
       " 7265: 9754,\n",
       " 7266: 8534,\n",
       " 7267: 7876,\n",
       " 7268: 7249,\n",
       " 7269: 8387,\n",
       " 7271: 8976,\n",
       " 7272: 6798,\n",
       " 7273: 6152,\n",
       " 7275: 6987,\n",
       " 7276: 7926,\n",
       " 7277: 9536,\n",
       " 7278: 6758,\n",
       " 7279: 9364,\n",
       " 7280: 7455,\n",
       " 7281: 8393,\n",
       " 7282: 7298,\n",
       " 7283: 7616,\n",
       " 7284: 7095,\n",
       " 7285: 8440,\n",
       " 7286: 9092,\n",
       " 7287: 8626,\n",
       " 7288: 9485,\n",
       " 7290: 8939,\n",
       " 7291: 10349,\n",
       " 7293: 8432,\n",
       " 7294: 10271,\n",
       " 7295: 7331,\n",
       " 7296: 8380,\n",
       " 7297: 8110,\n",
       " 7298: 7405,\n",
       " 7299: 8606,\n",
       " 7300: 8103,\n",
       " 7301: 8690,\n",
       " 7302: 7692,\n",
       " 7304: 11010,\n",
       " 7306: 7590,\n",
       " 7307: 9093,\n",
       " 7308: 7974,\n",
       " 7309: 8330,\n",
       " 7310: 9545,\n",
       " 7311: 6776,\n",
       " 7312: 7842,\n",
       " 7313: 7438,\n",
       " 7314: 8623,\n",
       " 7316: 8594,\n",
       " 7317: 9067,\n",
       " 7318: 7904,\n",
       " 7319: 8012,\n",
       " 7320: 7950,\n",
       " 7321: 8772,\n",
       " 7324: 7147,\n",
       " 7325: 6832,\n",
       " 7327: 6287,\n",
       " 7329: 7404,\n",
       " 7330: 7168,\n",
       " 7331: 9309,\n",
       " 7332: 7870,\n",
       " 7333: 6468,\n",
       " 7335: 7211,\n",
       " 7336: 7831,\n",
       " 7337: 8611,\n",
       " 7338: 7783,\n",
       " 7340: 7286,\n",
       " 7341: 9669,\n",
       " 7342: 6953,\n",
       " 7343: 8767,\n",
       " 7344: 9450,\n",
       " 7345: 7647,\n",
       " 7346: 9893,\n",
       " 7347: 7795,\n",
       " 7348: 6881,\n",
       " 7349: 7422,\n",
       " 7350: 9737,\n",
       " 7353: 10617,\n",
       " 7354: 7727,\n",
       " 7355: 9306,\n",
       " 7357: 6504,\n",
       " 7358: 6706,\n",
       " 7359: 9418,\n",
       " 7360: 9398,\n",
       " 7362: 8468,\n",
       " 7363: 7769,\n",
       " 7364: 7363,\n",
       " 7366: 8684,\n",
       " 7367: 8269,\n",
       " 7369: 7088,\n",
       " 7370: 5639,\n",
       " 7371: 7895,\n",
       " 7372: 6205,\n",
       " 7373: 10444,\n",
       " 7374: 7832,\n",
       " 7376: 7779,\n",
       " 7377: 7182,\n",
       " 7378: 9011,\n",
       " 7380: 6628,\n",
       " 7381: 6207,\n",
       " 7382: 6865,\n",
       " 7383: 10709,\n",
       " 7384: 8860,\n",
       " 7385: 6950,\n",
       " 7386: 8826,\n",
       " 7388: 10327,\n",
       " 7389: 8625,\n",
       " 7390: 9146,\n",
       " 7393: 6668,\n",
       " 7394: 11624,\n",
       " 7395: 10232,\n",
       " 7396: 6490,\n",
       " 7397: 7805,\n",
       " 7400: 7808,\n",
       " 7401: 9187,\n",
       " 7402: 7985,\n",
       " 7403: 9224,\n",
       " 7404: 6541,\n",
       " 7405: 9469,\n",
       " 7407: 10015,\n",
       " 7408: 9581,\n",
       " 7409: 7498,\n",
       " 7410: 9236,\n",
       " 7411: 10947,\n",
       " 7412: 6422,\n",
       " 7413: 8255,\n",
       " 7414: 7402,\n",
       " 7415: 8317,\n",
       " 7416: 9219,\n",
       " 7417: 6671,\n",
       " 7419: 9231,\n",
       " 7420: 8690,\n",
       " 7421: 7559,\n",
       " 7423: 9859,\n",
       " 7424: 9907,\n",
       " 7425: 9222,\n",
       " 7427: 10040,\n",
       " 7428: 7317,\n",
       " 7429: 8808,\n",
       " 7430: 7437,\n",
       " 7431: 6225,\n",
       " 7432: 8423,\n",
       " 7433: 7229,\n",
       " 7434: 8678,\n",
       " 7435: 7505,\n",
       " 7437: 10048,\n",
       " 7438: 6602,\n",
       " 7439: 9896,\n",
       " 7440: 7025,\n",
       " 7441: 7806,\n",
       " 7442: 8549,\n",
       " 7443: 8652,\n",
       " 7445: 9239,\n",
       " 7446: 6728,\n",
       " 7449: 9234,\n",
       " 7450: 6523,\n",
       " 7451: 7571,\n",
       " 7452: 9926,\n",
       " 7453: 8848,\n",
       " 7454: 6465,\n",
       " 7455: 9047,\n",
       " 7456: 9153,\n",
       " 7457: 9235,\n",
       " 7458: 6393,\n",
       " 7459: 5135,\n",
       " 7460: 7564,\n",
       " 7461: 7226,\n",
       " 7463: 8509,\n",
       " 7464: 7355,\n",
       " 7465: 9204,\n",
       " 7466: 7713,\n",
       " 7467: 8769,\n",
       " 7468: 8052,\n",
       " 7470: 7321,\n",
       " 7471: 8496,\n",
       " 7472: 9645,\n",
       " 7474: 6982,\n",
       " 7475: 6779,\n",
       " 7476: 8393,\n",
       " 7477: 6553,\n",
       " 7478: 9212,\n",
       " 7479: 6861,\n",
       " 7480: 7933,\n",
       " 7481: 6468,\n",
       " 7482: 6327,\n",
       " 7483: 10164,\n",
       " 7484: 6183,\n",
       " 7485: 8896,\n",
       " 7486: 7639,\n",
       " 7488: 8477,\n",
       " 7489: 9042,\n",
       " 7490: 7508,\n",
       " 7491: 8967,\n",
       " 7492: 9136,\n",
       " 7493: 8748,\n",
       " 7494: 7651,\n",
       " 7495: 6786,\n",
       " 7496: 8715,\n",
       " 7497: 9131,\n",
       " 7499: 6407,\n",
       " 7500: 8728,\n",
       " 7501: 8935,\n",
       " 7502: 9400,\n",
       " 7503: 9651,\n",
       " 7504: 8101,\n",
       " 7505: 6658,\n",
       " 7506: 8793,\n",
       " 7507: 7798,\n",
       " 7508: 7170,\n",
       " 7509: 8353,\n",
       " 7510: 6884,\n",
       " 7511: 8229,\n",
       " 7512: 8441,\n",
       " 7513: 8544,\n",
       " 7514: 7292,\n",
       " 7515: 8579,\n",
       " 7516: 7392,\n",
       " 7517: 8941,\n",
       " 7518: 7691,\n",
       " 7519: 9183,\n",
       " 7520: 7006,\n",
       " 7521: 9036,\n",
       " 7522: 9236,\n",
       " 7523: 7222,\n",
       " 7524: 8042,\n",
       " 7525: 5931,\n",
       " 7526: 7803,\n",
       " 7527: 6129,\n",
       " 7528: 7388,\n",
       " 7529: 8100,\n",
       " 7530: 8965,\n",
       " 7531: 6217,\n",
       " 7532: 6026,\n",
       " 7533: 7880,\n",
       " 7534: 8153,\n",
       " 7535: 9377,\n",
       " 7536: 11125,\n",
       " 7537: 6992,\n",
       " 7538: 9225,\n",
       " 7539: 7979,\n",
       " 7540: 7640,\n",
       " 7541: 7134,\n",
       " 7542: 8193,\n",
       " 7544: 8093,\n",
       " 7545: 7433,\n",
       " 7546: 7439,\n",
       " 7548: 9806,\n",
       " 7549: 9037,\n",
       " 7550: 7743,\n",
       " 7551: 7069,\n",
       " 7552: 8440,\n",
       " 7553: 7124,\n",
       " 7554: 7056,\n",
       " 7556: 6902,\n",
       " 7559: 7514,\n",
       " 7561: 12162,\n",
       " 7563: 5724,\n",
       " 7564: 8617,\n",
       " 7565: 8341,\n",
       " 7566: 6901,\n",
       " 7568: 8319,\n",
       " 7570: 8679,\n",
       " 7572: 6226,\n",
       " 7574: 7532,\n",
       " 7575: 7456,\n",
       " 7576: 6208,\n",
       " 7577: 7609,\n",
       " 7579: 7613,\n",
       " 7580: 7934,\n",
       " 7581: 8799,\n",
       " 7582: 7438,\n",
       " 7583: 7790,\n",
       " 7585: 7321,\n",
       " 7587: 9605,\n",
       " 7588: 7211,\n",
       " 7589: 5933,\n",
       " 7590: 6100,\n",
       " 7591: 9254,\n",
       " 7592: 11334,\n",
       " 7593: 6831,\n",
       " 7596: 8377,\n",
       " 7598: 7870,\n",
       " 7600: 7885,\n",
       " 7601: 7873,\n",
       " 7602: 7648,\n",
       " 7603: 7873,\n",
       " 7604: 8736,\n",
       " 7605: 8874,\n",
       " 7606: 6725,\n",
       " 7607: 6972,\n",
       " 7608: 6360,\n",
       " 7609: 6725,\n",
       " 7610: 11863,\n",
       " 7611: 10329,\n",
       " 7613: 9383,\n",
       " 7615: 10038,\n",
       " 7616: 8487,\n",
       " 7617: 7067,\n",
       " 7619: 8777,\n",
       " 7620: 8102,\n",
       " 7621: 6774,\n",
       " 7622: 9052,\n",
       " 7623: 7774,\n",
       " 7624: 7825,\n",
       " 7625: 8902,\n",
       " 7626: 8104,\n",
       " 7627: 7959,\n",
       " 7628: 8283,\n",
       " 7629: 8934,\n",
       " 7630: 6514,\n",
       " 7631: 7319,\n",
       " 7633: 7504,\n",
       " 7634: 7414,\n",
       " 7635: 7758,\n",
       " 8020: 12885,\n",
       " 8021: 9389,\n",
       " 8022: 9619,\n",
       " 8023: 9118,\n",
       " 8024: 8449,\n",
       " 8026: 9638,\n",
       " 8027: 9746,\n",
       " 8030: 8527,\n",
       " 8034: 6029,\n",
       " 8038: 10778,\n",
       " 8040: 8867,\n",
       " 8043: 7719,\n",
       " 8044: 7108,\n",
       " 8045: 9001,\n",
       " 8046: 11531,\n",
       " 8052: 10906,\n",
       " 8057: 9664,\n",
       " 8058: 10123,\n",
       " 8060: 6492,\n",
       " 8063: 10369,\n",
       " 8064: 8274,\n",
       " 8065: 11768,\n",
       " 8069: 9023,\n",
       " 8070: 12092,\n",
       " 8071: 7757,\n",
       " 8076: 11306,\n",
       " 8079: 11509,\n",
       " 8085: 10673,\n",
       " 8086: 8181,\n",
       " 8088: 8566,\n",
       " 8089: 10714,\n",
       " 8090: 10337,\n",
       " 8091: 8021,\n",
       " 8092: 10376,\n",
       " 8095: 9678,\n",
       " 8096: 10645,\n",
       " 8097: 9705,\n",
       " 8098: 6713,\n",
       " 8099: 7165,\n",
       " 8105: 11992,\n",
       " 8106: 6768,\n",
       " 8107: 9206,\n",
       " 8109: 10894,\n",
       " 8114: 11158,\n",
       " 8122: 12869,\n",
       " 8125: 7393,\n",
       " 11135: 14908,\n",
       " 2811: 4436,\n",
       " 3532: 5549,\n",
       " 3927: 5649,\n",
       " 5102: 3974,\n",
       " 6221: 8114,\n",
       " 7636: 9803,\n",
       " 7646: 9215,\n",
       " 7664: 2373,\n",
       " 9008: 3983,\n",
       " 9307: 7060,\n",
       " 9356: 6163,\n",
       " 9546: 3232,\n",
       " 11143: 10496,\n",
       " 12057: 3526,\n",
       " 12657: 4229,\n",
       " 14637: 766,\n",
       " 17199: 5368,\n",
       " 619: 6144,\n",
       " 1839: 5637,\n",
       " 1917: 5977,\n",
       " 1932: 3038,\n",
       " 2069: 4586,\n",
       " 2128: 8858,\n",
       " 2395: 3416,\n",
       " 2758: 5988,\n",
       " 3072: 4799,\n",
       " 3378: 3048,\n",
       " 3527: 7327,\n",
       " 3907: 5993,\n",
       " 4203: 2065,\n",
       " 5737: 7565,\n",
       " 5860: 5860,\n",
       " 6702: 7210,\n",
       " 8467: 6840,\n",
       " 8676: 6671,\n",
       " 9411: 5724,\n",
       " 9968: 4528,\n",
       " 10273: 7025,\n",
       " 10398: 4911,\n",
       " ...}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(g.degree())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 : Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For test size:  0.8\n",
      "For test size:  0.6\n",
      "For test size:  0.4\n",
      "For test size:  0.2\n"
     ]
    }
   ],
   "source": [
    "testSize = [0.8,0.6,0.4,0.2]\n",
    "accuracy_list_NB = []\n",
    "precision_list_NB = []\n",
    "recall_list_NB = []\n",
    "conf_mat_NB = []\n",
    "\n",
    "#loading the feature matrix and labels \n",
    "feature_matrix = np.load('D:/NLP Project/ICA/feature_matrix.npy')\n",
    "class_labels = np.load('D:/NLP Project/ICA/class_lables.npy')\n",
    "indices = np.arange(len(feature_matrix))\n",
    "\n",
    "for k in testSize:\n",
    "    print('For test size: ',k)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(feature_matrix, class_labels,test_size=k, random_state=0, stratify=class_labels)\n",
    "    clf = GaussianNB() # Bootstrapping using Naive Bayes as Base Classifier\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    confusion_mat = confusion_matrix(y_test,y_pred)\n",
    "\n",
    "    conf_mat_NB.append(confusion_mat)\n",
    "    accuracy_list_NB.append(metrics.accuracy_score(y_test,y_pred))\n",
    "    precision_list_NB.append(metrics.precision_score(y_test,y_pred,average='macro',zero_division=0))\n",
    "    recall_list_NB.append(metrics.recall_score(y_test,y_pred,average='macro'))\n",
    "\n",
    "    # Micro\n",
    "    precision_list_NB.append(metrics.precision_score(y_test,y_pred,average='micro',zero_division=0))\n",
    "    recall_list_NB.append(metrics.recall_score(y_test,y_pred,average='micro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.64', '0.64', '0.64', '0.66']\n",
      "['0.65', '0.64', '0.65', '0.64', '0.66', '0.64', '0.69', '0.66']\n",
      "['0.65', '0.64', '0.65', '0.64', '0.65', '0.64', '0.67', '0.66']\n",
      "[array([[2327,  425,  653,  147],\n",
      "       [ 510, 2068,  476,  335],\n",
      "       [ 899,  746, 2338,  131],\n",
      "       [  79,  511,  123, 2313]], dtype=int64), array([[1994,  178,  297,  195],\n",
      "       [ 540, 1300,  252,  450],\n",
      "       [1027,  296, 1556,  207],\n",
      "       [  65,  235,   66, 1903]], dtype=int64), array([[1421,   84,  126,  145],\n",
      "       [ 372,  775,  123,  425],\n",
      "       [ 737,  137,  980,  203],\n",
      "       [  35,  131,   26, 1321]], dtype=int64), array([[732,  34,  55,  67],\n",
      "       [171, 379,  60, 237],\n",
      "       [336,  60, 516, 117],\n",
      "       [  7,  52,   5, 693]], dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "accuracy_list_NB = [\"%.2f\" % elem for elem in accuracy_list_NB]\n",
    "precision_list_NB = [\"%.2f\" % elem for elem in precision_list_NB]\n",
    "recall_list_NB = [\"%.2f\" % elem for elem in recall_list_NB]\n",
    "\n",
    "print(accuracy_list_NB)\n",
    "print(precision_list_NB)\n",
    "print(recall_list_NB)\n",
    "print(conf_mat_NB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1 : ICA - NB with Label Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For test size:  0.8\n",
      "For test size:  0.6\n",
      "For test size:  0.4\n",
      "For test size:  0.2\n"
     ]
    }
   ],
   "source": [
    "##Bootstrapping\n",
    "testSize = [0.8,0.6,0.4,0.2]\n",
    "accuracy_list_ICA_Labels = []\n",
    "precision_list_ICA_Labels = []\n",
    "recall_list_ICA_Labels = []\n",
    "conf_mat_ICA_Labels = []\n",
    "\n",
    "feature_matrix = np.load('D:/NLP Project/ICA/feature_matrix.npy')\n",
    "class_labels = np.load('D:/NLP Project/ICA/class_lables.npy')\n",
    "indices = np.arange(len(feature_matrix))\n",
    "\n",
    "for k in testSize:\n",
    "    print('For test size: ',k)\n",
    "    X_train, X_test, y_train, y_test,idx_train,idx_test = train_test_split(feature_matrix, class_labels, indices,test_size=k, random_state=0, stratify=class_labels)\n",
    "    clf = GaussianNB() # Bootstrapping using Naive Bayes as Base Classifier\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test) # y-pred is bootstrapped labels\n",
    "    iter_labels = class_labels\n",
    "    np.put(iter_labels,idx_test,y_pred)  # updating labels of test data with the predecited labels \n",
    "    iter_labels_list = list(iter_labels)\n",
    "    distinct_labels = sorted(list(set(iter_labels_list)))\n",
    "\n",
    "    # ICA starting\n",
    "\n",
    "    adj_feats_train = np.zeros((len(X_train),len(distinct_labels)))\n",
    "    adj_feats_test  = np.zeros((len(X_test),len(distinct_labels)))\n",
    "\n",
    "    ########################################################################\n",
    "    ##constructing additional features, train and Iterate until stabilized##\n",
    "\n",
    "    #updating the adjacent features for training nodes\n",
    "    for i in range(len(idx_train)):\n",
    "        adjs = list(g[idx_train[i]])\n",
    "        adjs_threshold = []\n",
    "        cnt_of_ew1 = 0\n",
    "        for nei in adjs:\n",
    "            if g[idx_train[i]][nei]['edge_weight'] == 1:\n",
    "                cnt_of_ew1 += 1 # Count for single node\n",
    "        for nei in adjs:\n",
    "            if cnt_of_ew1 == g.degree[idx_train[i]] and g[idx_train[i]][nei]['edge_weight']==1:\n",
    "                adjs_threshold.append(nei)\n",
    "            if g[idx_train[i]][nei]['edge_weight']>1:\n",
    "                adjs_threshold.append(nei)\n",
    "        adjs_threshold = [int(nei) for nei in adjs_threshold]\n",
    "        labels_of_adjacent_nodes = [iter_labels_list[nei] for nei in adjs_threshold]\n",
    "\n",
    "        for j in range(len(distinct_labels)):\n",
    "            this_label = distinct_labels[j]\n",
    "            cnt_of_adjacent_labels = labels_of_adjacent_nodes.count(this_label) ## Voting by neighbor nodes.\n",
    "            adj_feats_train[i][this_label] = cnt_of_adjacent_labels\n",
    "        \n",
    "          \n",
    "    X_train_updated = np.concatenate((X_train,adj_feats_train),axis = 1)\n",
    "\n",
    "    #updating the adjancent features for test nodes\n",
    "    for i in range(len(idx_test)):\n",
    "        adjs = list(g[idx_test[i]])\n",
    "        adjs_threshold = []\n",
    "        cnt_of_ew1 = 0\n",
    "        for nei in adjs:\n",
    "            if g[idx_test[i]][nei]['edge_weight'] == 1:\n",
    "                cnt_of_ew1 += 1\n",
    "        for nei in adjs:\n",
    "            if cnt_of_ew1 == g.degree[idx_test[i]] and g[idx_test[i]][nei]['edge_weight']==1:\n",
    "                adjs_threshold.append(nei)\n",
    "            if g[idx_test[i]][nei]['edge_weight']>1:\n",
    "                adjs_threshold.append(nei) \n",
    "        adjs_threshold = [int(nei) for nei in adjs_threshold]\n",
    "        labels_of_adjacent_nodes = [iter_labels_list[nei] for nei in adjs_threshold]\n",
    "\n",
    "        for j in range(len(distinct_labels)):\n",
    "            this_label = distinct_labels[j]\n",
    "            cnt_of_adjacent_labels = labels_of_adjacent_nodes.count(this_label) ## Voting by neighbor nodes.\n",
    "            adj_feats_test[i][this_label] = cnt_of_adjacent_labels\n",
    "\n",
    "    X_test_updated = np.concatenate((X_test,adj_feats_test),axis = 1)  \n",
    "\n",
    "    #learning the new model on updated feature matrix with adjacent labels\n",
    "    clf_updated = GaussianNB()\n",
    "    clf_updated.fit(X_train_updated,y_train)\n",
    "    #print(\"\\nStarting ICA Loop: ...\\n\")\n",
    "    #staring the ICA inference loop\n",
    "    loop_var = 0\n",
    "    iter_var = 0\n",
    "    y_pred_current = y_pred\n",
    "    while (loop_var == 0 and iter_var < 15):\n",
    "            y_pred_updated = clf_updated.predict(X_test_updated)\n",
    "            if(np.array_equal(y_pred_current, y_pred_updated)):\n",
    "                #algorithm stabilized\n",
    "                #print(\"ICA Stabilized\")\n",
    "                loop_var = 1        \n",
    "            else:\n",
    "                loop_var = 0\n",
    "                iter_var += 1\n",
    "                #print(\"ICA Loop: \"+str(iter_var))\n",
    "                \n",
    "                #updating the labels for test nodes with new predictions\n",
    "                for i in range(len(idx_test)):\n",
    "                    iter_labels_list[idx_test[i]] = y_pred_updated[i]\n",
    "                \n",
    "                #updating the adjacent features for test nodes\n",
    "                for i in range(len(idx_test)):\n",
    "                    adjs = list(g[idx_test[i]])\n",
    "                    adjs_threshold = []\n",
    "                    cnt_of_ew1 = 0\n",
    "                    for nei in adjs:\n",
    "                        if g[idx_test[i]][nei]['edge_weight'] == 1:\n",
    "                            cnt_of_ew1 += 1\n",
    "                    for nei in adjs:\n",
    "                        if cnt_of_ew1 == g.degree[idx_test[i]] and g[idx_test[i]][nei]['edge_weight']==1:\n",
    "                            adjs_threshold.append(nei)\n",
    "                        if g[idx_test[i]][nei]['edge_weight']>1:\n",
    "                            adjs_threshold.append(nei) \n",
    "                    adjs_threshold = [int(nei) for nei in adjs_threshold]\n",
    "                    labels_of_adjacent_nodes = [iter_labels_list[nei] for nei in adjs_threshold]\n",
    "\n",
    "                    for j in range(len(distinct_labels)):\n",
    "                        this_label = distinct_labels[j]\n",
    "                        cnt_of_adjacent_labels = labels_of_adjacent_nodes.count(this_label) ## Voting by neighbor nodes.\n",
    "                        adj_feats_test[i][this_label] = cnt_of_adjacent_labels\n",
    "                                        \n",
    "                X_test_updated = np.concatenate((X_test,adj_feats_test),axis = 1)\n",
    "                y_pred_current = y_pred_updated   \n",
    "    \n",
    "    #print('No. of iterations ICA ran: ',iter_var)            \n",
    "    final_predictions = y_pred_updated\n",
    "\n",
    "    #print('\\nMetrics for Iterative Classification Algorithm for train size {:.1f}:\\n'.format(1-k))\n",
    "    # ICA\n",
    "    # Macro\n",
    "    confusion_mat = confusion_matrix(y_test,y_pred_updated)\n",
    "    conf_mat_ICA_Labels.append(confusion_mat)\n",
    "\n",
    "    accuracy_list_ICA_Labels.append(metrics.accuracy_score(y_test,y_pred_updated))\n",
    "    precision_list_ICA_Labels.append(metrics.precision_score(y_test,y_pred_updated,average='macro',zero_division=0))\n",
    "    recall_list_ICA_Labels.append(metrics.recall_score(y_test,y_pred_updated,average='macro'))\n",
    "\n",
    "    # Micro\n",
    "    precision_list_ICA_Labels.append(metrics.precision_score(y_test,y_pred_updated,average='micro',zero_division=0))\n",
    "    recall_list_ICA_Labels.append(metrics.recall_score(y_test,y_pred_updated,average='micro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.69', '0.79', '0.83', '0.85']\n",
      "['0.70', '0.69', '0.79', '0.79', '0.83', '0.83', '0.85', '0.85']\n",
      "['0.69', '0.69', '0.79', '0.79', '0.83', '0.83', '0.84', '0.85']\n",
      "[array([[2377,  350,  737,   88],\n",
      "       [ 398, 2167,  550,  274],\n",
      "       [ 690,  556, 2778,   90],\n",
      "       [  57,  484,  115, 2370]], dtype=int64), array([[2324,  186,  266,   46],\n",
      "       [ 208, 1985,  304,  261],\n",
      "       [ 395,  232, 2061,   84],\n",
      "       [  85,  143,   33, 1948]], dtype=int64), array([[1798,  125,  128,   36],\n",
      "       [ 109, 1281,  140,  136],\n",
      "       [ 187,  123, 1314,   38],\n",
      "       [  63,   95,   30, 1438]], dtype=int64), array([[975,  72,  61,  10],\n",
      "       [ 45, 607,  53,  70],\n",
      "       [ 74,  40, 617,  23],\n",
      "       [ 42,  37,   8, 787]], dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "accuracy_list_ICA_Labels = [\"%.2f\" % elem for elem in accuracy_list_ICA_Labels]\n",
    "precision_list_ICA_Labels = [\"%.2f\" % elem for elem in precision_list_ICA_Labels]\n",
    "recall_list_ICA_Labels = [\"%.2f\" % elem for elem in recall_list_ICA_Labels]\n",
    "\n",
    "print(accuracy_list_ICA_Labels)\n",
    "print(precision_list_ICA_Labels)\n",
    "print(recall_list_ICA_Labels)\n",
    "print(conf_mat_ICA_Labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2 : ICA - NB with Sum of Edge Weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For test size:  0.8\n",
      "For test size:  0.6\n",
      "For test size:  0.4\n",
      "For test size:  0.2\n"
     ]
    }
   ],
   "source": [
    "testSize = [0.8,0.6,0.4,0.2]\n",
    "accuracy_list_ICA_EW= []\n",
    "precision_list_ICA_EW = []\n",
    "recall_list_ICA_EW = []\n",
    "conf_mat_ICA_EW = []\n",
    "\n",
    "feature_matrix = np.load('D:/NLP Project/ICA/feature_matrix.npy')\n",
    "class_labels = np.load('D:/NLP Project/ICA/class_lables.npy')\n",
    "indices = np.arange(len(feature_matrix))\n",
    "\n",
    "for k in testSize:\n",
    "    print('For test size: ',k)\n",
    "    X_train, X_test, y_train, y_test,idx_train,idx_test = train_test_split(feature_matrix, class_labels, indices,test_size=k, random_state=0, stratify=class_labels)\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    iter_labels = class_labels\n",
    "    np.put(iter_labels,idx_test,y_pred)  # updating labels of test data with the predecited labels \n",
    "    iter_labels_list = list(iter_labels)\n",
    "    distinct_labels = sorted(list(set(iter_labels_list)))\n",
    "\n",
    "    # ICA starting\n",
    "\n",
    "    adj_feats_train = np.zeros((len(X_train),len(distinct_labels)))\n",
    "    adj_feats_test  = np.zeros((len(X_test),len(distinct_labels)))\n",
    "\n",
    "    ########################################################################\n",
    "    ##constructing additional features, train and Iterate until stabilized##\n",
    "\n",
    "    #updating the adjancent features for training nodes\n",
    "    for i in range(len(idx_train)):\n",
    "        adjs = list(g[idx_train[i]])\n",
    "        adjs_threshold = []\n",
    "        cnt_of_ew1 = 0\n",
    "        for nei in adjs:\n",
    "            if g[idx_train[i]][nei]['edge_weight'] == 1:\n",
    "                cnt_of_ew1 += 1\n",
    "        for nei in adjs:\n",
    "            if cnt_of_ew1 == g.degree[idx_train[i]] and g[idx_train[i]][nei]['edge_weight']==1:\n",
    "                adjs_threshold.append(nei)\n",
    "            if g[idx_train[i]][nei]['edge_weight']>1:\n",
    "                adjs_threshold.append(nei) \n",
    "        adjs_threshold = [int(nei) for nei in adjs_threshold]\n",
    "        edge_weight_adj_nodes = [0]*len(distinct_labels)\n",
    "\n",
    "        for j in range(len(adjs_threshold)):\n",
    "            this_label = iter_labels_list[adjs_threshold[j]]\n",
    "            edge_weight_adj_nodes[this_label] +=  int(g[idx_train[i]][adjs_threshold[j]]['edge_weight'])/len(g[idx_train[i]])\n",
    "            adj_feats_train[i][this_label] = edge_weight_adj_nodes[this_label]\n",
    "        \n",
    "          \n",
    "    X_train_updated = np.concatenate((X_train,adj_feats_train),axis = 1)\n",
    "\n",
    "    #updating the adjancent features for test nodes\n",
    "    for i in range(len(idx_test)):\n",
    "        adjs = list(g[idx_test[i]])\n",
    "        adjs_threshold = []\n",
    "        cnt_of_ew1 = 0\n",
    "        for nei in adjs:\n",
    "            if g[idx_test[i]][nei]['edge_weight'] == 1:\n",
    "                cnt_of_ew1 += 1\n",
    "        for nei in adjs:\n",
    "            if cnt_of_ew1 == g.degree[idx_test[i]] and g[idx_test[i]][nei]['edge_weight']==1:\n",
    "                adjs_threshold.append(nei)\n",
    "            if g[idx_test[i]][nei]['edge_weight']>1:\n",
    "                adjs_threshold.append(nei) \n",
    "        adjs_threshold = [int(nei) for nei in adjs_threshold]\n",
    "        edge_weight_adj_nodes = [0]*len(distinct_labels)\n",
    "\n",
    "        for j in range(len(adjs_threshold)):\n",
    "            this_label = iter_labels_list[adjs_threshold[j]]\n",
    "            edge_weight_adj_nodes[this_label] +=  int(g[idx_test[i]][adjs_threshold[j]]['edge_weight'])/len(g[idx_test[i]])\n",
    "            adj_feats_test[i][this_label] = edge_weight_adj_nodes[this_label]\n",
    "\n",
    "    X_test_updated = np.concatenate((X_test,adj_feats_test),axis = 1)  \n",
    "\n",
    "    #learning the new model on updated feature matrix with adjacent labels\n",
    "    clf_updated = GaussianNB()\n",
    "    clf_updated.fit(X_train_updated,y_train)\n",
    "    #print(\"\\nStarting ICA Loop: ...\\n\")\n",
    "    #staring the ICA inference loop\n",
    "    loop_var = 0\n",
    "    iter_var = 0\n",
    "    y_pred_current = y_pred\n",
    "    while (loop_var == 0 and iter_var < 15):\n",
    "            y_pred_updated = clf_updated.predict(X_test_updated)\n",
    "            if(np.array_equal(y_pred_current, y_pred_updated)):\n",
    "                #algorithm stabilized\n",
    "                #print(\"ICA Stabilized\")\n",
    "                loop_var = 1        \n",
    "            else:\n",
    "                loop_var = 0\n",
    "                iter_var += 1\n",
    "                #print(\"ICA Loop: \"+str(iter_var))\n",
    "                \n",
    "                #updating the labels for test nodes with new predictions\n",
    "                for i in range(len(idx_test)):\n",
    "                    iter_labels_list[idx_test[i]] = y_pred_updated[i]\n",
    "                \n",
    "                #updating the adjancent features for test nodes\n",
    "                for i in range(len(idx_test)):\n",
    "                    adjs = list(g[idx_test[i]])\n",
    "                    adjs_threshold = []\n",
    "                    cnt_of_ew1 = 0\n",
    "                    for nei in adjs:\n",
    "                        if g[idx_test[i]][nei]['edge_weight'] == 1:\n",
    "                            cnt_of_ew1 += 1\n",
    "                    for nei in adjs:\n",
    "                        if cnt_of_ew1 == g.degree[idx_test[i]] and g[idx_test[i]][nei]['edge_weight']==1:\n",
    "                            adjs_threshold.append(nei)\n",
    "                        if g[idx_test[i]][nei]['edge_weight']>1:\n",
    "                            adjs_threshold.append(nei) \n",
    "                    adjs_threshold = [int(nei) for nei in adjs_threshold]\n",
    "                    edge_weight_adj_nodes = [0]*len(distinct_labels)\n",
    "\n",
    "                    for j in range(len(adjs_threshold)):\n",
    "                        this_label = iter_labels_list[adjs_threshold[j]]\n",
    "                        edge_weight_adj_nodes[this_label] +=  int(g[idx_test[i]][adjs_threshold[j]]['edge_weight'])/len(g[idx_test[i]])\n",
    "                        adj_feats_test[i][this_label] = edge_weight_adj_nodes[this_label]     \n",
    "                                \n",
    "                X_test_updated = np.concatenate((X_test,adj_feats_test),axis = 1)\n",
    "                y_pred_current = y_pred_updated   \n",
    "    #print('No. of iterations ICA ran: ',iter_var)            \n",
    "    final_predictions = y_pred_updated\n",
    "\n",
    "    #print('ICA - Edge Weight Confusion matrix:\\n')\n",
    "    confusion_mat = confusion_matrix(y_test,y_pred_updated)\n",
    "    conf_mat_ICA_EW.append(confusion_mat)\n",
    "    #print(confusion_mat)\n",
    "\n",
    "    #print('\\nMetrics for Iterative Classification Algorithm for train size {:.1f}:\\n'.format(1-k))\n",
    "    # ICA\n",
    "    # Macro\n",
    "    accuracy_list_ICA_EW.append(metrics.accuracy_score(y_test,y_pred_updated))\n",
    "    precision_list_ICA_EW.append(metrics.precision_score(y_test,y_pred_updated,average='macro',zero_division=0))\n",
    "    recall_list_ICA_EW.append(metrics.recall_score(y_test,y_pred_updated,average='macro'))\n",
    "\n",
    "    # Micro\n",
    "    precision_list_ICA_EW.append(metrics.precision_score(y_test,y_pred_updated,average='micro',zero_division=0))\n",
    "    recall_list_ICA_EW.append(metrics.recall_score(y_test,y_pred_updated,average='micro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.64', '0.75', '0.81', '0.86']\n",
      "['0.65', '0.64', '0.75', '0.75', '0.82', '0.81', '0.87', '0.86']\n",
      "['0.65', '0.64', '0.76', '0.75', '0.81', '0.81', '0.85', '0.86']\n",
      "[array([[2327,  425,  653,  147],\n",
      "       [ 510, 2068,  476,  335],\n",
      "       [ 899,  746, 2338,  131],\n",
      "       [  79,  511,  123, 2313]], dtype=int64), array([[2341,  149,  206,  126],\n",
      "       [ 375, 1782,  219,  382],\n",
      "       [ 566,  232, 1842,  132],\n",
      "       [  55,  162,   40, 1952]], dtype=int64), array([[1905,   44,   56,   82],\n",
      "       [ 190, 1156,   83,  237],\n",
      "       [ 333,  144, 1124,   61],\n",
      "       [  27,   33,   14, 1552]], dtype=int64), array([[1070,    7,    7,   34],\n",
      "       [  61,  568,   26,  120],\n",
      "       [ 119,   52,  548,   35],\n",
      "       [   7,   11,    3,  853]], dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "accuracy_list_ICA_EW = [\"%.2f\" % elem for elem in accuracy_list_ICA_EW]\n",
    "precision_list_ICA_EW = [\"%.2f\" % elem for elem in precision_list_ICA_EW]\n",
    "recall_list_ICA_EW = [\"%.2f\" % elem for elem in recall_list_ICA_EW]\n",
    "\n",
    "print(accuracy_list_ICA_EW)\n",
    "print(precision_list_ICA_EW)\n",
    "print(recall_list_ICA_EW)\n",
    "print(conf_mat_ICA_EW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3 : ICA-NB with Combined Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For test size:  0.8\n",
      "No. of iterations ICA ran:  1\n",
      "For test size:  0.6\n",
      "No. of iterations ICA ran:  1\n",
      "For test size:  0.4\n",
      "No. of iterations ICA ran:  1\n",
      "For test size:  0.2\n",
      "No. of iterations ICA ran:  1\n"
     ]
    }
   ],
   "source": [
    "testSize = [0.8,0.6,0.4,0.2]\n",
    "accuracy_list_ICA_Combined = []\n",
    "precision_list_ICA_Combined = []\n",
    "recall_list_ICA_Combined = []\n",
    "conf_matrix_ICA_Combined = []\n",
    "\n",
    "feature_matrix = np.load('D:/NLP Project/ICA/feature_matrix.npy')\n",
    "class_labels = np.load('D:/NLP Project/ICA/class_lables.npy')\n",
    "indices = np.arange(len(feature_matrix))\n",
    "\n",
    "for k in testSize:\n",
    "    print('For test size: ',k)\n",
    "    X_train, X_test, y_train, y_test,idx_train,idx_test = train_test_split(feature_matrix, class_labels, indices,test_size=k, random_state=0, stratify=class_labels)\n",
    "    clf = GaussianNB()\n",
    "    clf.fit(X_train,y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    iter_labels = class_labels\n",
    "    np.put(iter_labels,idx_test,y_pred)  # updating labels of test data with the predecited labels \n",
    "    iter_labels_list = list(iter_labels)\n",
    "    distinct_labels = sorted(list(set(iter_labels_list)))\n",
    "\n",
    "    # ICA starting\n",
    "\n",
    "    adj_feats_train = np.zeros((len(X_train),2*len(distinct_labels))) # Multiply by 2, since we have 8 additional features combined.\n",
    "    adj_feats_test  = np.zeros((len(X_test),2*len(distinct_labels)))\n",
    "\n",
    "    ########################################################################\n",
    "    ##constructing additional features, train and Iterate until stabilized##\n",
    "\n",
    "    #updating the adjancent features for training nodes\n",
    "    for i in range(len(idx_train)):       \n",
    "        adjs = list(g[idx_train[i]])\n",
    "        adjs_threshold = []\n",
    "        cnt_of_ew1 = 0\n",
    "        for nei in adjs:\n",
    "            if g[idx_train[i]][nei]['edge_weight'] == 1:\n",
    "                cnt_of_ew1 += 1\n",
    "        for nei in adjs:\n",
    "            if cnt_of_ew1 == g.degree[idx_train[i]] and g[idx_train[i]][nei]['edge_weight']==1:\n",
    "                adjs_threshold.append(nei)\n",
    "            if g[idx_train[i]][nei]['edge_weight']>1:\n",
    "                adjs_threshold.append(nei) \n",
    "        adjs_threshold = [int(nei) for nei in adjs_threshold]\n",
    "        labels_of_adjacent_nodes = [iter_labels_list[nei] for nei in adjs_threshold]\n",
    "        edge_weight_adj_nodes = [0]*len(distinct_labels)\n",
    "        \n",
    "        for j in range(len(adjs_threshold)):\n",
    "            this_label = iter_labels_list[adjs_threshold[j]]\n",
    "            edge_weight_adj_nodes[this_label] +=  int(g[idx_train[i]][adjs_threshold[j]]['edge_weight'])/len(g[idx_train[i]])\n",
    "            adj_feats_train[i][this_label] = edge_weight_adj_nodes[this_label]\n",
    "        \n",
    "        for k in range(len(distinct_labels)):\n",
    "            this_label = distinct_labels[k]\n",
    "            cnt_of_adjacent_labels = labels_of_adjacent_nodes.count(this_label) ## Voting by neighbor nodes.\n",
    "            adj_feats_train[i][this_label+len(distinct_labels)] = cnt_of_adjacent_labels\n",
    "          \n",
    "    X_train_updated = np.concatenate((X_train,adj_feats_train),axis = 1)\n",
    "\n",
    "    #updating the adjancent features for test nodes\n",
    "    for i in range(len(idx_test)):       \n",
    "        adjs = list(g[idx_test[i]])\n",
    "        adjs_threshold = []\n",
    "        cnt_of_ew1 = 0\n",
    "        for nei in adjs:\n",
    "            if g[idx_test[i]][nei]['edge_weight'] == 1:\n",
    "                cnt_of_ew1 += 1\n",
    "        for nei in adjs:\n",
    "            if cnt_of_ew1 == g.degree[idx_test[i]] and g[idx_test[i]][nei]['edge_weight']==1:\n",
    "                adjs_threshold.append(nei)\n",
    "            if g[idx_test[i]][nei]['edge_weight']>1:\n",
    "                adjs_threshold.append(nei) \n",
    "        adjs_threshold = [int(nei) for nei in adjs_threshold]\n",
    "        labels_of_adjacent_nodes = [iter_labels_list[nei] for nei in adjs_threshold]\n",
    "        edge_weight_adj_nodes = [0]*len(distinct_labels)\n",
    "        \n",
    "        for j in range(len(adjs_threshold)):\n",
    "            this_label = iter_labels_list[adjs_threshold[j]]\n",
    "            edge_weight_adj_nodes[this_label] +=  int(g[idx_test[i]][adjs_threshold[j]]['edge_weight'])/len(g[idx_test[i]])\n",
    "            adj_feats_test[i][this_label] = edge_weight_adj_nodes[this_label]\n",
    "        \n",
    "        for k in range(len(distinct_labels)):\n",
    "            this_label = distinct_labels[k]\n",
    "            cnt_of_adjacent_labels = labels_of_adjacent_nodes.count(this_label) ## Voting by neighbor nodes.\n",
    "            adj_feats_test[i][this_label+len(distinct_labels)] = cnt_of_adjacent_labels\n",
    "\n",
    "    X_test_updated = np.concatenate((X_test,adj_feats_test),axis = 1)  \n",
    "\n",
    "    #learning the new model on updated feature matrix with adjacent labels\n",
    "    clf_updated = GaussianNB()\n",
    "    clf_updated.fit(X_train_updated,y_train)\n",
    "    #print(\"\\nStarting ICA Loop: ...\\n\")\n",
    "    #staring the ICA inference loop\n",
    "    loop_var = 0\n",
    "    iter_var = 0\n",
    "    y_pred_current = y_pred\n",
    "    while (loop_var == 0 and iter_var < 15):\n",
    "            y_pred_updated = clf_updated.predict(X_test_updated)\n",
    "            if(np.array_equal(y_pred_current, y_pred_updated)):\n",
    "                #algorithm stabilized\n",
    "                #print(\"ICA Stabilized\")\n",
    "                loop_var = 1        \n",
    "            else:\n",
    "                loop_var = 0\n",
    "                iter_var += 1\n",
    "                #print(\"ICA Loop: \"+str(iter_var))\n",
    "                \n",
    "                #updating the labels for test nodes with new predictions\n",
    "                for i in range(len(idx_test)):\n",
    "                    iter_labels_list[idx_test[i]] = y_pred_updated[i]\n",
    "                \n",
    "                #updating the adjancent features for test nodes\n",
    "                for i in range(len(idx_test)):       \n",
    "                    adjs = list(g[idx_test[i]])\n",
    "                    adjs_threshold = []\n",
    "                    cnt_of_ew1 = 0\n",
    "                    for nei in adjs:\n",
    "                        if g[idx_test[i]][nei]['edge_weight'] == 1:\n",
    "                            cnt_of_ew1 += 1\n",
    "                    for nei in adjs:\n",
    "                        if cnt_of_ew1 == g.degree[idx_test[i]] and g[idx_test[i]][nei]['edge_weight']==1:\n",
    "                            adjs_threshold.append(nei)\n",
    "                        if g[idx_test[i]][nei]['edge_weight']>1:\n",
    "                            adjs_threshold.append(nei) \n",
    "                    adjs_threshold = [int(nei) for nei in adjs_threshold]\n",
    "                    labels_of_adjacent_nodes = [iter_labels_list[nei] for nei in adjs_threshold]\n",
    "                    edge_weight_adj_nodes = [0]*len(distinct_labels)\n",
    "                    \n",
    "                    for j in range(len(adjs_threshold)):\n",
    "                        this_label = iter_labels_list[adjs_threshold[j]]\n",
    "                        edge_weight_adj_nodes[this_label] +=  int(g[idx_test[i]][adjs_threshold[j]]['edge_weight'])/len(g[idx_test[i]])\n",
    "                        adj_feats_test[i][this_label] = edge_weight_adj_nodes[this_label]\n",
    "                    \n",
    "                    for k in range(len(distinct_labels)):\n",
    "                        this_label = distinct_labels[k]\n",
    "                        cnt_of_adjacent_labels = labels_of_adjacent_nodes.count(this_label) ## Voting by neighbor nodes.\n",
    "                        adj_feats_test[i][this_label+len(distinct_labels)] = cnt_of_adjacent_labels       \n",
    "                                \n",
    "                X_test_updated = np.concatenate((X_test,adj_feats_test),axis = 1)\n",
    "                y_pred_current = y_pred_updated   \n",
    "    print('No. of iterations ICA ran: ',iter_var)            \n",
    "    final_predictions = y_pred_updated\n",
    "\n",
    "    #print('ICA - Edge Weight Confusion matrix:\\n')\n",
    "    confusion_mat = confusion_matrix(y_test,y_pred_updated)\n",
    "    conf_matrix_ICA_Combined.append(confusion_mat)\n",
    "    #print(confusion_mat)\n",
    "\n",
    "    #print('\\nMetrics for Iterative Classification Algorithm for train size {:.1f}:\\n'.format(1-k))\n",
    "    # ICA\n",
    "    # Macro\n",
    "    accuracy_list_ICA_Combined.append(metrics.accuracy_score(y_test,y_pred_updated))\n",
    "    precision_list_ICA_Combined.append(metrics.precision_score(y_test,y_pred_updated,average='macro',zero_division=0))\n",
    "    recall_list_ICA_Combined.append(metrics.recall_score(y_test,y_pred_updated,average='macro'))\n",
    "\n",
    "    # Micro\n",
    "    precision_list_ICA_Combined.append(metrics.precision_score(y_test,y_pred_updated,average='micro',zero_division=0))\n",
    "    recall_list_ICA_Combined.append(metrics.recall_score(y_test,y_pred_updated,average='micro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.69', '0.79', '0.83', '0.85']\n",
      "['0.70', '0.69', '0.79', '0.79', '0.83', '0.83', '0.85', '0.85']\n",
      "['0.69', '0.69', '0.79', '0.79', '0.83', '0.83', '0.84', '0.85']\n",
      "[array([[2378,  350,  737,   87],\n",
      "       [ 397, 2169,  550,  273],\n",
      "       [ 690,  556, 2778,   90],\n",
      "       [  56,  484,  115, 2371]], dtype=int64), array([[2324,  186,  266,   46],\n",
      "       [ 208, 1985,  304,  261],\n",
      "       [ 395,  232, 2061,   84],\n",
      "       [  85,  143,   33, 1948]], dtype=int64), array([[1798,  125,  128,   36],\n",
      "       [ 110, 1282,  138,  136],\n",
      "       [ 187,  122, 1315,   38],\n",
      "       [  63,   95,   30, 1438]], dtype=int64), array([[975,  72,  61,  10],\n",
      "       [ 45, 607,  53,  70],\n",
      "       [ 74,  40, 617,  23],\n",
      "       [ 42,  37,   8, 787]], dtype=int64)]\n"
     ]
    }
   ],
   "source": [
    "accuracy_list_ICA_Combined = [\"%.2f\" % elem for elem in accuracy_list_ICA_Combined]\n",
    "precision_list_ICA_Combined = [\"%.2f\" % elem for elem in precision_list_ICA_Combined]\n",
    "recall_list_ICA_Combined = [\"%.2f\" % elem for elem in recall_list_ICA_Combined]\n",
    "\n",
    "print(accuracy_list_ICA_Combined)\n",
    "print(precision_list_ICA_Combined)\n",
    "print(recall_list_ICA_Combined)\n",
    "print(conf_matrix_ICA_Combined)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cc5f70855ac006f3de45a3cc3b9e7d8d53845e50458809cb162b0174266dec97"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
