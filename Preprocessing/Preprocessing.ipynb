{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import string \n",
    "import re\n",
    "import itertools\n",
    "import pandas as ps \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "from itertools import combinations, permutations\n",
    "from cleantext import clean   # !pip install clean-text\n",
    "ps.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data file containing subset of AG Corpus of News Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ps.read_csv('D:/NLP Project/Data/NewsData.csv')\n",
    "df.drop(columns=['image','pubdate','video','rank'],axis=1,inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping health documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.category!='Health'] # To maintain equal distribution between class of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding URLS of Documents to Numeric scale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding URL's into unique ID's\n",
    "label_encoder = LabelEncoder()\n",
    "df['url'] = label_encoder.fit_transform(df['url'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18544"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sci/Tech         5244\n",
       "Entertainment    4685\n",
       "Business         4583\n",
       "Sports           4032\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing of Source, Title and Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion to Lower case.\n",
    "\n",
    "df['source'] = df['source'].str.lower()\n",
    "df['title'] = df['title'].str.lower()\n",
    "df['description'] = df['description'].str.lower()\n",
    "\n",
    "#Stripped the string.\n",
    "\n",
    "df['source'] = df['source'].str.strip()\n",
    "df['title'] = df['title'].str.strip()\n",
    "df['description'] = df['description'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean text in title and description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = df.apply(lambda row: clean(row['title'],fix_unicode=True,no_urls=True,to_ascii=True,lower=True,no_emails=True,),axis=1)\n",
    "df['description'] = df.apply(lambda row: clean(row['description'],fix_unicode=True,no_urls=True,to_ascii=True,lower=True,no_emails=True),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title'] = df['title'].apply(lambda x:''.join([i for i in x if i not in string.punctuation]))\n",
    "df['description'] = df['description'].apply(lambda x:''.join([i for i in x if i not in string.punctuation]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenized_title'] = df.apply(lambda row: word_tokenize(row['title']),axis=1)  # Adding in a new column\n",
    "df['tokenized_description'] = df.apply(lambda row: word_tokenize(row['description']),axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine tokens from title and description of a document "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['doc'] = df['tokenized_title'] + df['tokenized_description']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of tokens in a doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [roddick, smacks, voltchkov, with, a, record, ...\n",
       "1        [sony, hit, by, ps3, launch, delay, tokyo, reu...\n",
       "2        [word, of, oversupply, from, opec, punctures, ...\n",
       "3        [google, maps, boosts, public, transportation,...\n",
       "4        [vetri, made, the, right, call, by, going, to,...\n",
       "                               ...                        \n",
       "18539    [sorry, not, so, hard, for, elton, john, sir, ...\n",
       "18540    [franz, win, good, for, rock, music, glasgow, ...\n",
       "18541    [stewart, mcdonald, raise, their, standards, r...\n",
       "18542    [merck, in, 700, million, schizophrenia, deal,...\n",
       "18543    [salvation, army, prepared, for, tough, fundra...\n",
       "Name: doc, Length: 18544, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['doc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopword & Non-alphanumeric characters removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop word, digits,non-english alphabets removal\n",
    "stop_words = set(stopwords.words('english'))\n",
    "for i in range(len(df)):\n",
    "    df['doc'][i] = [w for w in df['doc'][i] if not w in stop_words]\n",
    "    df['doc'][i] = list(filter(lambda w: re.search(\"^[a-zA-Z]{3,}$\", w) is not None, df['doc'][i]))\n",
    "    df['doc'][i] = [w for w in df['doc'][i] if not w.isdigit()] # Remove digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removal of Pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removal of Pronouns (Singular and Plural)\n",
    "for i in range(len(df)):\n",
    "    tagged_doc = pos_tag(df.doc[i])\n",
    "    edited_doc = [word for word,tag in tagged_doc if tag!= 'NNP' and tag!= 'NNPS']\n",
    "    df.doc[i] = edited_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming & Lemmatization of tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming and lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "for i in range(len(df)):\n",
    "    for j in range(len(df['doc'][i])):\n",
    "        df['doc'][i][j] = lemmatizer.lemmatize(df['doc'][i][j])\n",
    "        df['doc'][i][j] = stemmer.stem(df['doc'][i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    df['doc'][i] = [w for w in df['doc'][i] if not w in stop_words]\n",
    "    df['doc'][i] = list(filter(lambda w: re.search(\"^[a-zA-Z]{3,}$\", w) is not None, df['doc'][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word count in each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count'] = df.apply(lambda row: Counter(row['doc']),axis=1)  # Adding in a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        {'roddick': 2, 'smack': 1, 'voltchkov': 2, 're...\n",
       "1        {'soni': 2, 'hit': 1, 'launch': 2, 'delay': 2,...\n",
       "2        {'word': 1, 'oversuppli': 1, 'opec': 2, 'punct...\n",
       "3        {'googl': 1, 'map': 1, 'boost': 1, 'public': 1...\n",
       "4        {'vetri': 2, 'made': 1, 'right': 1, 'call': 2,...\n",
       "                               ...                        \n",
       "18539    {'sorri': 1, 'hard': 1, 'elton': 2, 'john': 2,...\n",
       "18540    {'franz': 2, 'win': 1, 'good': 1, 'rock': 2, '...\n",
       "18541    {'stewart': 2, 'mcdonald': 2, 'rais': 1, 'stan...\n",
       "18542    {'merck': 2, 'million': 2, 'schizophrenia': 2,...\n",
       "18543    {'salvat': 2, 'armi': 2, 'prepar': 2, 'tough':...\n",
       "Name: word_count, Length: 18544, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['word_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total tokens from the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_dict = Counter()\n",
    "\n",
    "for i in range(len(df)):\n",
    "    counter1 = Counter(df['word_count'][i])\n",
    "    add_dict += counter1\n",
    "    \n",
    "final_dict = dict(add_dict) # Sum of all word_count dictionaries is final dictionary.\n",
    "#print(final_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34275"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminating tokens with frequency less than 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in list(final_dict.items()): # Threshold to eliminate in-frequent words.\n",
    "    if v < 20:\n",
    "        del final_dict[k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length of BOW (Bag Of Words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3664"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roddick': 56,\n",
       " 'record': 730,\n",
       " 'serv': 97,\n",
       " 'american': 588,\n",
       " 'andi': 66,\n",
       " 'improv': 213,\n",
       " 'servic': 945,\n",
       " 'mark': 262,\n",
       " 'blast': 77,\n",
       " 'win': 1027,\n",
       " 'vladimir': 24,\n",
       " 'friday': 1072,\n",
       " 'earn': 380,\n",
       " 'unit': 808,\n",
       " 'state': 953,\n",
       " 'earli': 288,\n",
       " 'lead': 756,\n",
       " 'belaru': 20,\n",
       " 'davi': 110,\n",
       " 'cup': 436,\n",
       " 'semifin': 75,\n",
       " 'world': 1381,\n",
       " 'group': 737,\n",
       " 'soni': 220,\n",
       " 'hit': 612,\n",
       " 'launch': 607,\n",
       " 'delay': 154,\n",
       " 'tokyo': 217,\n",
       " 'reuter': 3332,\n",
       " 'corp': 812,\n",
       " 'hrefurl': 5363,\n",
       " 'share': 759,\n",
       " 'open': 931,\n",
       " 'percent': 745,\n",
       " 'lower': 251,\n",
       " 'yen': 58,\n",
       " 'thursday': 1180,\n",
       " 'said': 3154,\n",
       " 'would': 835,\n",
       " 'european': 335,\n",
       " 'playstat': 44,\n",
       " 'game': 1488,\n",
       " 'machin': 93,\n",
       " 'march': 176,\n",
       " 'novemb': 152,\n",
       " 'miss': 309,\n",
       " 'holiday': 153,\n",
       " 'shop': 139,\n",
       " 'season': 679,\n",
       " 'key': 221,\n",
       " 'market': 933,\n",
       " 'word': 117,\n",
       " 'opec': 82,\n",
       " 'oil': 857,\n",
       " 'price': 883,\n",
       " 'london': 406,\n",
       " 'eas': 92,\n",
       " 'today': 528,\n",
       " 'head': 366,\n",
       " 'crude': 141,\n",
       " 'trader': 67,\n",
       " 'continu': 383,\n",
       " 'take': 925,\n",
       " 'profit': 729,\n",
       " 'year': 1885,\n",
       " 'ralli': 168,\n",
       " 'googl': 539,\n",
       " 'map': 71,\n",
       " 'boost': 254,\n",
       " 'public': 325,\n",
       " 'transport': 39,\n",
       " 'data': 453,\n",
       " 'blog': 275,\n",
       " 'enhanc': 55,\n",
       " 'inform': 249,\n",
       " 'isnt': 87,\n",
       " 'avail': 173,\n",
       " 'citi': 519,\n",
       " 'yet': 167,\n",
       " 'though': 95,\n",
       " 'made': 434,\n",
       " 'right': 443,\n",
       " 'call': 584,\n",
       " 'fall': 421,\n",
       " 'peter': 70,\n",
       " 'readi': 185,\n",
       " 'answer': 76,\n",
       " 'phone': 630,\n",
       " 'await': 57,\n",
       " 'entir': 56,\n",
       " 'life': 363,\n",
       " 'nikkei': 53,\n",
       " 'stock': 886,\n",
       " 'averag': 115,\n",
       " 'rose': 293,\n",
       " 'monday': 1114,\n",
       " 'investor': 355,\n",
       " 'encourag': 35,\n",
       " 'seek': 257,\n",
       " 'bargain': 26,\n",
       " 'recoveri': 48,\n",
       " 'retreat': 27,\n",
       " 'high': 432,\n",
       " 'demand': 243,\n",
       " 'quick': 39,\n",
       " 'result': 265,\n",
       " 'airbu': 42,\n",
       " 'subsidi': 22,\n",
       " 'disput': 99,\n",
       " 'pari': 165,\n",
       " 'dec': 207,\n",
       " 'afp': 242,\n",
       " 'want': 435,\n",
       " 'rapid': 34,\n",
       " 'progress': 69,\n",
       " 'resolv': 37,\n",
       " 'union': 229,\n",
       " 'aid': 152,\n",
       " 'rival': 317,\n",
       " 'aircraft': 60,\n",
       " 'maker': 454,\n",
       " 'boe': 88,\n",
       " 'trade': 491,\n",
       " 'organis': 27,\n",
       " 'talk': 489,\n",
       " 'produc': 285,\n",
       " 'soar': 73,\n",
       " 'top': 713,\n",
       " 'pop': 141,\n",
       " 'chart': 83,\n",
       " 'irish': 41,\n",
       " 'rocker': 34,\n",
       " 'straight': 156,\n",
       " 'sunday': 742,\n",
       " 'new': 4265,\n",
       " 'singl': 147,\n",
       " 'sometim': 47,\n",
       " 'cant': 106,\n",
       " 'make': 935,\n",
       " 'competit': 179,\n",
       " 'latest': 284,\n",
       " 'brewer': 35,\n",
       " 'bounc': 34,\n",
       " 'back': 786,\n",
       " 'beat': 419,\n",
       " 'cub': 62,\n",
       " 'chicago': 249,\n",
       " 'rebound': 123,\n",
       " 'tough': 85,\n",
       " 'defeat': 160,\n",
       " 'day': 819,\n",
       " 'earlier': 137,\n",
       " 'milwauke': 39,\n",
       " 'pound': 91,\n",
       " 'saturday': 672,\n",
       " 'ben': 69,\n",
       " 'sheet': 20,\n",
       " 'victori': 522,\n",
       " 'green': 206,\n",
       " 'light': 133,\n",
       " 'bridg': 37,\n",
       " 'heart': 119,\n",
       " 'washington': 490,\n",
       " 'regul': 166,\n",
       " 'announc': 738,\n",
       " 'approv': 184,\n",
       " 'artifici': 23,\n",
       " 'design': 278,\n",
       " 'keep': 318,\n",
       " 'patient': 48,\n",
       " 'aliv': 40,\n",
       " 'leav': 204,\n",
       " 'compani': 1941,\n",
       " 'chairman': 216,\n",
       " 'chief': 489,\n",
       " 'execut': 508,\n",
       " 'cloth': 46,\n",
       " 'retail': 352,\n",
       " 'store': 415,\n",
       " 'internet': 619,\n",
       " 'oper': 505,\n",
       " 'contract': 289,\n",
       " 'time': 1131,\n",
       " 'front': 96,\n",
       " 'column': 34,\n",
       " 'delight': 26,\n",
       " 'restaur': 37,\n",
       " 'jun': 41,\n",
       " 'arriv': 194,\n",
       " 'calif': 204,\n",
       " 'may': 1023,\n",
       " 'foot': 95,\n",
       " 'wild': 93,\n",
       " 'hair': 28,\n",
       " 'author': 216,\n",
       " 'caus': 181,\n",
       " 'death': 175,\n",
       " 'rapper': 44,\n",
       " 'known': 125,\n",
       " 'die': 194,\n",
       " 'manhattan': 39,\n",
       " 'studio': 177,\n",
       " 'sever': 272,\n",
       " 'conduct': 51,\n",
       " 'medic': 124,\n",
       " 'test': 398,\n",
       " 'offici': 548,\n",
       " 'northern': 103,\n",
       " 'rock': 199,\n",
       " 'sink': 37,\n",
       " 'govern': 507,\n",
       " 'nation': 758,\n",
       " 'bank': 611,\n",
       " 'threaten': 128,\n",
       " 'british': 321,\n",
       " 'prime': 121,\n",
       " 'minist': 214,\n",
       " 'alreadi': 177,\n",
       " 'srcurl': 5729,\n",
       " 'ship': 119,\n",
       " 'wireless': 331,\n",
       " 'mous': 36,\n",
       " 'sourc': 280,\n",
       " 'classfeedflar': 396,\n",
       " 'divimg': 391,\n",
       " 'rescu': 63,\n",
       " 'return': 472,\n",
       " 'woman': 343,\n",
       " 'arrest': 163,\n",
       " 'dog': 82,\n",
       " 'let': 198,\n",
       " 'chase': 51,\n",
       " 'fox': 108,\n",
       " 'owner': 158,\n",
       " 'sheriff': 33,\n",
       " 'deputi': 33,\n",
       " 'pick': 158,\n",
       " 'anim': 129,\n",
       " 'activist': 39,\n",
       " 'face': 429,\n",
       " 'feloni': 24,\n",
       " 'theft': 40,\n",
       " 'charg': 526,\n",
       " 'look': 613,\n",
       " 'person': 264,\n",
       " 'street': 366,\n",
       " 'view': 173,\n",
       " 'imag': 197,\n",
       " 'cnet': 57,\n",
       " 'newscom': 44,\n",
       " 'best': 353,\n",
       " 'featur': 238,\n",
       " 'illustr': 21,\n",
       " 'element': 26,\n",
       " 'reveal': 137,\n",
       " 'speci': 55,\n",
       " 'tree': 43,\n",
       " 'scottish': 30,\n",
       " 'root': 27,\n",
       " 'plant': 145,\n",
       " 'expert': 130,\n",
       " 'discov': 83,\n",
       " 'varieti': 57,\n",
       " 'uniqu': 32,\n",
       " 'bruce': 30,\n",
       " 'island': 122,\n",
       " 'scotland': 51,\n",
       " 'west': 222,\n",
       " 'coast': 125,\n",
       " 'found': 300,\n",
       " 'remot': 45,\n",
       " 'corner': 26,\n",
       " 'north': 222,\n",
       " 'slam': 68,\n",
       " 'devil': 73,\n",
       " 'ray': 80,\n",
       " 'angel': 604,\n",
       " 'rout': 82,\n",
       " 'alignleft': 1325,\n",
       " 'point': 532,\n",
       " 'sky': 59,\n",
       " 'grand': 144,\n",
       " 'tampa': 59,\n",
       " 'bay': 140,\n",
       " 'seventh': 51,\n",
       " 'inning': 225,\n",
       " 'basebal': 278,\n",
       " 'juli': 214,\n",
       " 'anaheim': 45,\n",
       " 'lewi': 38,\n",
       " 'aap': 834,\n",
       " 'career': 182,\n",
       " 'first': 1540,\n",
       " 'fourth': 195,\n",
       " 'capit': 196,\n",
       " 'two': 1202,\n",
       " 'controversi': 108,\n",
       " 'rule': 381,\n",
       " 'base': 246,\n",
       " 'bill': 306,\n",
       " 'nightpbr': 62,\n",
       " 'clearal': 1324,\n",
       " 'fire': 288,\n",
       " 'charlott': 50,\n",
       " 'church': 62,\n",
       " 'steve': 133,\n",
       " 'observ': 50,\n",
       " 'sep': 55,\n",
       " 'battl': 249,\n",
       " 'morn': 138,\n",
       " 'injuri': 130,\n",
       " 'report': 1403,\n",
       " 'rooki': 78,\n",
       " 'henri': 39,\n",
       " 'ireland': 53,\n",
       " 'lot': 143,\n",
       " 'written': 35,\n",
       " 'tom': 136,\n",
       " 'lehman': 22,\n",
       " 'ryder': 69,\n",
       " 'past': 356,\n",
       " 'month': 639,\n",
       " 'much': 350,\n",
       " 'good': 325,\n",
       " 'toshiba': 61,\n",
       " 'join': 232,\n",
       " 'recal': 96,\n",
       " 'blame': 76,\n",
       " 'bad': 126,\n",
       " 'memori': 152,\n",
       " 'issu': 297,\n",
       " 'modul': 20,\n",
       " 'use': 914,\n",
       " 'dozen': 81,\n",
       " 'laptop': 136,\n",
       " 'model': 171,\n",
       " 'potenti': 145,\n",
       " 'affect': 76,\n",
       " 'notebook': 85,\n",
       " 'comput': 576,\n",
       " 'space': 433,\n",
       " 'station': 205,\n",
       " 'crew': 92,\n",
       " 'begin': 246,\n",
       " 'spacewalk': 28,\n",
       " 'russia': 146,\n",
       " 'astronaut': 93,\n",
       " 'buy': 546,\n",
       " 'mass': 76,\n",
       " 'paper': 100,\n",
       " 'medium': 400,\n",
       " 'inc': 1104,\n",
       " 'yesterday': 618,\n",
       " 'massachusett': 62,\n",
       " 'daili': 161,\n",
       " 'newspap': 111,\n",
       " 'weekli': 37,\n",
       " 'wife': 116,\n",
       " 'lay': 37,\n",
       " 'investig': 271,\n",
       " 'houston': 178,\n",
       " 'feder': 553,\n",
       " 'prosecutor': 72,\n",
       " 'whether': 169,\n",
       " 'former': 557,\n",
       " 'illeg': 82,\n",
       " 'sold': 142,\n",
       " 'went': 109,\n",
       " 'lawyer': 123,\n",
       " 'wednesday': 1124,\n",
       " 'court': 531,\n",
       " 'dvd': 192,\n",
       " 'suit': 189,\n",
       " 'judg': 250,\n",
       " 'dismiss': 68,\n",
       " 'case': 317,\n",
       " 'men': 174,\n",
       " 'violat': 87,\n",
       " 'copyright': 64,\n",
       " 'direct': 139,\n",
       " 'say': 1235,\n",
       " 'technolog': 677,\n",
       " 'hack': 40,\n",
       " 'doesnt': 128,\n",
       " 'constitut': 25,\n",
       " 'copi': 68,\n",
       " 'protect': 202,\n",
       " 'place': 274,\n",
       " 'drug': 413,\n",
       " 'agenc': 245,\n",
       " 'devic': 258,\n",
       " 'fusion': 27,\n",
       " 'food': 159,\n",
       " 'administr': 148,\n",
       " 'electr': 90,\n",
       " 'bone': 29,\n",
       " 'growth': 335,\n",
       " 'success': 200,\n",
       " 'rate': 427,\n",
       " 'popul': 39,\n",
       " 'financ': 113,\n",
       " 'rise': 470,\n",
       " 'pressur': 132,\n",
       " 'age': 132,\n",
       " 'vital': 25,\n",
       " 'quickli': 76,\n",
       " 'fix': 119,\n",
       " 'social': 153,\n",
       " 'safeti': 129,\n",
       " 'net': 230,\n",
       " 'step': 231,\n",
       " 'rais': 339,\n",
       " 'full': 126,\n",
       " 'retir': 137,\n",
       " 'benefit': 121,\n",
       " 'reserv': 203,\n",
       " 'alan': 59,\n",
       " 'greenspan': 50,\n",
       " 'hold': 334,\n",
       " 'madison': 20,\n",
       " 'watch': 216,\n",
       " 'tee': 23,\n",
       " 'shot': 220,\n",
       " 'eighth': 36,\n",
       " 'hole': 81,\n",
       " 'third': 385,\n",
       " 'round': 242,\n",
       " 'southern': 102,\n",
       " 'farm': 72,\n",
       " 'bureau': 24,\n",
       " 'classic': 143,\n",
       " 'golf': 97,\n",
       " 'sept': 253,\n",
       " 'play': 655,\n",
       " 'like': 690,\n",
       " 'man': 377,\n",
       " 'suddenli': 30,\n",
       " 'rememb': 37,\n",
       " 'need': 401,\n",
       " 'big': 449,\n",
       " 'doubl': 158,\n",
       " 'maintain': 62,\n",
       " 'final': 541,\n",
       " 'club': 203,\n",
       " 'cours': 102,\n",
       " 'left': 410,\n",
       " 'atop': 29,\n",
       " 'leader': 277,\n",
       " 'board': 247,\n",
       " 'run': 667,\n",
       " 'tour': 220,\n",
       " 'card': 164,\n",
       " 'marathon': 42,\n",
       " 'given': 116,\n",
       " 'suspend': 133,\n",
       " 'sentenc': 63,\n",
       " 'greek': 53,\n",
       " 'jail': 92,\n",
       " 'euro': 112,\n",
       " 'fine': 121,\n",
       " 'push': 208,\n",
       " 'olymp': 308,\n",
       " 'runner': 24,\n",
       " 'road': 171,\n",
       " 'comcast': 25,\n",
       " 'portabl': 65,\n",
       " 'digit': 290,\n",
       " 'video': 416,\n",
       " 'player': 533,\n",
       " 'largest': 330,\n",
       " 'cabl': 113,\n",
       " 'consum': 412,\n",
       " 'electron': 241,\n",
       " 'industri': 522,\n",
       " 'show': 952,\n",
       " 'appl': 415,\n",
       " 'ipod': 147,\n",
       " 'system': 629,\n",
       " 'debut': 160,\n",
       " 'attract': 88,\n",
       " 'alert': 38,\n",
       " 'patch': 75,\n",
       " 'tuesday': 1179,\n",
       " 'calendar': 23,\n",
       " 'south': 275,\n",
       " 'park': 192,\n",
       " 'creator': 38,\n",
       " 'send': 193,\n",
       " 'save': 184,\n",
       " 'seven': 169,\n",
       " 'ago': 207,\n",
       " 'parker': 23,\n",
       " 'matt': 55,\n",
       " 'stone': 57,\n",
       " 'brought': 73,\n",
       " 'porn': 26,\n",
       " 'toronto': 143,\n",
       " 'intern': 529,\n",
       " 'film': 632,\n",
       " 'festiv': 142,\n",
       " 'padr': 30,\n",
       " 'cardin': 78,\n",
       " 'ryan': 55,\n",
       " 'goahead': 24,\n",
       " 'none': 33,\n",
       " 'san': 431,\n",
       " 'diego': 93,\n",
       " 'loui': 113,\n",
       " 'night': 661,\n",
       " 'playoff': 138,\n",
       " 'hope': 381,\n",
       " 'end': 708,\n",
       " 'streak': 106,\n",
       " 'abn': 24,\n",
       " 'member': 220,\n",
       " 'bought': 78,\n",
       " 'letter': 76,\n",
       " 'amsterdam': 28,\n",
       " 'italian': 75,\n",
       " 'dutch': 72,\n",
       " 'hedg': 49,\n",
       " 'fund': 252,\n",
       " 'urg': 122,\n",
       " 'sale': 850,\n",
       " 'break': 188,\n",
       " 'accord': 498,\n",
       " 'regulatori': 28,\n",
       " 'file': 713,\n",
       " 'deni': 120,\n",
       " 'intent': 38,\n",
       " 'polic': 240,\n",
       " 'concert': 124,\n",
       " 'januari': 166,\n",
       " 'herald': 45,\n",
       " 'fla': 103,\n",
       " 'mar': 80,\n",
       " 'band': 126,\n",
       " 'perform': 288,\n",
       " 'pete': 21,\n",
       " 'ticket': 74,\n",
       " 'schedul': 152,\n",
       " 'ventur': 94,\n",
       " 'invest': 278,\n",
       " 'strategi': 97,\n",
       " 'money': 183,\n",
       " 'giant': 489,\n",
       " 'increasingli': 56,\n",
       " 'decid': 175,\n",
       " 'financi': 312,\n",
       " 'risk': 181,\n",
       " 'involv': 110,\n",
       " 'held': 156,\n",
       " 'late': 223,\n",
       " 'goal': 236,\n",
       " 'minut': 122,\n",
       " 'yield': 34,\n",
       " 'draw': 101,\n",
       " 'soldier': 69,\n",
       " 'bodi': 104,\n",
       " 'expect': 616,\n",
       " 'home': 730,\n",
       " 'resid': 82,\n",
       " 'kill': 323,\n",
       " 'countri': 384,\n",
       " 'iraq': 272,\n",
       " 'famili': 193,\n",
       " 'armi': 89,\n",
       " 'spokeswoman': 36,\n",
       " 'deal': 757,\n",
       " 'put': 339,\n",
       " 'lenovo': 34,\n",
       " 'global': 325,\n",
       " 'stage': 165,\n",
       " 'began': 115,\n",
       " 'decad': 127,\n",
       " 'ltd': 133,\n",
       " 'littl': 261,\n",
       " 'deliveri': 39,\n",
       " 'academ': 20,\n",
       " 'research': 460,\n",
       " 'beij': 103,\n",
       " 'defenc': 34,\n",
       " 'infring': 46,\n",
       " 'claim': 379,\n",
       " 'softwar': 800,\n",
       " 'allow': 287,\n",
       " 'user': 493,\n",
       " 'exchang': 177,\n",
       " 'music': 645,\n",
       " 'movi': 441,\n",
       " 'onlin': 592,\n",
       " 'differ': 172,\n",
       " 'landmark': 36,\n",
       " 'fit': 69,\n",
       " 'trial': 169,\n",
       " 'hous': 394,\n",
       " 'order': 270,\n",
       " 'gener': 436,\n",
       " 'kidnap': 27,\n",
       " 'oppon': 49,\n",
       " 'militari': 106,\n",
       " 'briefli': 32,\n",
       " 'oprah': 24,\n",
       " 'book': 318,\n",
       " 'premier': 150,\n",
       " 'great': 206,\n",
       " 'debat': 125,\n",
       " 'hollywood': 336,\n",
       " 'decemb': 124,\n",
       " 'earth': 120,\n",
       " 'german': 150,\n",
       " 'nativ': 40,\n",
       " 'toll': 35,\n",
       " 'next': 691,\n",
       " 'select': 80,\n",
       " 'mario': 27,\n",
       " 'areut': 342,\n",
       " 'televis': 318,\n",
       " 'host': 215,\n",
       " 'assembl': 47,\n",
       " 'coach': 502,\n",
       " 'staff': 141,\n",
       " 'carolina': 107,\n",
       " 'flight': 111,\n",
       " 'control': 241,\n",
       " 'tri': 389,\n",
       " 'moscow': 45,\n",
       " 'june': 257,\n",
       " 'russian': 184,\n",
       " 'termin': 24,\n",
       " 'told': 165,\n",
       " 'marlin': 56,\n",
       " 'drop': 288,\n",
       " 'philli': 46,\n",
       " 'greet': 29,\n",
       " 'teammat': 72,\n",
       " 'howard': 57,\n",
       " 'solo': 24,\n",
       " 'florida': 230,\n",
       " 'dolphin': 110,\n",
       " 'stadium': 159,\n",
       " 'miami': 184,\n",
       " 'catcher': 31,\n",
       " 'ross': 24,\n",
       " 'eric': 55,\n",
       " 'one': 1387,\n",
       " 'lift': 165,\n",
       " 'philadelphia': 137,\n",
       " 'match': 248,\n",
       " 'cash': 152,\n",
       " 'businessman': 21,\n",
       " 'hunter': 38,\n",
       " 'pledg': 47,\n",
       " 'donat': 55,\n",
       " 'brief': 88,\n",
       " 'exploit': 37,\n",
       " 'window': 326,\n",
       " 'server': 224,\n",
       " 'flaw': 83,\n",
       " 'french': 149,\n",
       " 'cinema': 29,\n",
       " 'act': 140,\n",
       " 'mobil': 577,\n",
       " 'signal': 71,\n",
       " 'theatr': 28,\n",
       " 'prevent': 113,\n",
       " 'audienc': 65,\n",
       " 'still': 438,\n",
       " 'without': 237,\n",
       " 'leagu': 387,\n",
       " 'manag': 665,\n",
       " 'divis': 162,\n",
       " 'block': 136,\n",
       " 'grant': 62,\n",
       " 'request': 67,\n",
       " 'partner': 155,\n",
       " 'form': 119,\n",
       " 'sell': 415,\n",
       " 'give': 453,\n",
       " 'effort': 229,\n",
       " 'athen': 155,\n",
       " 'better': 239,\n",
       " 'ever': 157,\n",
       " 'row': 75,\n",
       " 'eight': 117,\n",
       " 'gold': 219,\n",
       " 'took': 214,\n",
       " 'silver': 42,\n",
       " 'way': 503,\n",
       " 'committe': 84,\n",
       " 'saw': 62,\n",
       " 'medal': 101,\n",
       " 'across': 182,\n",
       " 'event': 156,\n",
       " 'mani': 353,\n",
       " 'collect': 122,\n",
       " 'statement': 94,\n",
       " 'propos': 222,\n",
       " 'acquisit': 139,\n",
       " 'express': 88,\n",
       " 'script': 35,\n",
       " 'higher': 269,\n",
       " 'offer': 677,\n",
       " 'spring': 101,\n",
       " 'fashion': 123,\n",
       " 'week': 1048,\n",
       " 'alta': 186,\n",
       " 'wear': 47,\n",
       " 'outfit': 20,\n",
       " 'york': 1423,\n",
       " 'shape': 34,\n",
       " 'howev': 56,\n",
       " 'loos': 21,\n",
       " 'news': 637,\n",
       " 'million': 1054,\n",
       " 'search': 579,\n",
       " 'plan': 1040,\n",
       " 'librari': 71,\n",
       " 'project': 247,\n",
       " 'four': 403,\n",
       " 'univers': 270,\n",
       " 'robert': 130,\n",
       " 'scene': 83,\n",
       " 'analyst': 206,\n",
       " 'pittsburgh': 100,\n",
       " 'steeler': 55,\n",
       " 'nfl': 228,\n",
       " 'activ': 153,\n",
       " 'iphon': 231,\n",
       " 'read': 118,\n",
       " 'att': 128,\n",
       " 'custom': 371,\n",
       " 'everi': 143,\n",
       " 'busi': 905,\n",
       " 'articl': 33,\n",
       " 'check': 121,\n",
       " 'origin': 116,\n",
       " 'content': 130,\n",
       " 'network': 706,\n",
       " 'came': 149,\n",
       " 'noth': 66,\n",
       " 'larg': 134,\n",
       " 'dark': 52,\n",
       " 'safe': 64,\n",
       " 'brother': 58,\n",
       " 'rest': 81,\n",
       " 'fell': 238,\n",
       " 'sleep': 22,\n",
       " 'wake': 62,\n",
       " 'cbsmw': 34,\n",
       " 'thirdquart': 92,\n",
       " 'forecast': 206,\n",
       " 'quarter': 414,\n",
       " 'sign': 429,\n",
       " 'second': 731,\n",
       " 'tap': 45,\n",
       " 'star': 575,\n",
       " 'histor': 60,\n",
       " 'epic': 20,\n",
       " 'quest': 33,\n",
       " 'product': 742,\n",
       " 'tale': 50,\n",
       " 'legendari': 27,\n",
       " 'warrior': 30,\n",
       " 'princess': 23,\n",
       " 'gasolin': 38,\n",
       " 'fuel': 147,\n",
       " 'southeast': 22,\n",
       " 'denver': 61,\n",
       " 'declin': 173,\n",
       " 'colorado': 74,\n",
       " 'steadi': 46,\n",
       " 'increas': 336,\n",
       " 'summer': 128,\n",
       " 'cent': 84,\n",
       " 'last': 1035,\n",
       " 'challeng': 222,\n",
       " 'homeland': 25,\n",
       " 'secur': 705,\n",
       " 'depart': 216,\n",
       " 'releas': 586,\n",
       " 'account': 190,\n",
       " 'offic': 477,\n",
       " 'startup': 60,\n",
       " 'chip': 286,\n",
       " 'introduc': 140,\n",
       " 'processor': 89,\n",
       " 'develop': 617,\n",
       " 'three': 657,\n",
       " 'energi': 240,\n",
       " 'alignrighta': 158,\n",
       " 'targetblank': 197,\n",
       " 'img': 344,\n",
       " 'alt': 372,\n",
       " 'alignrightap': 123,\n",
       " 'compar': 60,\n",
       " 'semi': 27,\n",
       " 'possibl': 245,\n",
       " 'embed': 29,\n",
       " 'equip': 89,\n",
       " 'telecommun': 71,\n",
       " 'aerospac': 24,\n",
       " 'dan': 57,\n",
       " 'cofound': 29,\n",
       " 'pthe': 245,\n",
       " 'power': 371,\n",
       " 'architectur': 34,\n",
       " 'licens': 125,\n",
       " 'ibm': 340,\n",
       " 'advanc': 215,\n",
       " 'micro': 45,\n",
       " 'core': 72,\n",
       " 'duo': 40,\n",
       " 'intel': 280,\n",
       " 'wont': 163,\n",
       " 'directli': 31,\n",
       " 'compet': 97,\n",
       " 'amd': 90,\n",
       " 'initi': 123,\n",
       " 'measur': 90,\n",
       " 'independ': 76,\n",
       " 'effici': 44,\n",
       " 'dynam': 34,\n",
       " 'suppli': 192,\n",
       " 'older': 34,\n",
       " 'start': 624,\n",
       " 'stop': 193,\n",
       " 'flow': 26,\n",
       " 'process': 168,\n",
       " 'also': 480,\n",
       " 'clock': 30,\n",
       " 'gate': 103,\n",
       " 'get': 962,\n",
       " 'level': 189,\n",
       " 'within': 128,\n",
       " 'insid': 109,\n",
       " 'els': 36,\n",
       " 'realli': 102,\n",
       " 'done': 93,\n",
       " 'mayb': 51,\n",
       " 'target': 223,\n",
       " 'later': 97,\n",
       " 'includ': 519,\n",
       " 'could': 832,\n",
       " 'find': 351,\n",
       " 'wider': 26,\n",
       " 'blade': 24,\n",
       " 'even': 433,\n",
       " 'help': 701,\n",
       " 'richard': 99,\n",
       " 'senior': 125,\n",
       " 'peopl': 624,\n",
       " 'concern': 232,\n",
       " 'budget': 71,\n",
       " 'figur': 100,\n",
       " 'sens': 60,\n",
       " 'saidp': 187,\n",
       " 'previous': 62,\n",
       " 'vice': 104,\n",
       " 'presid': 605,\n",
       " 'acquir': 197,\n",
       " 'spent': 73,\n",
       " 'microprocessor': 27,\n",
       " 'santa': 54,\n",
       " 'california': 238,\n",
       " 'work': 656,\n",
       " 'sampl': 20,\n",
       " 'evalu': 20,\n",
       " 'kit': 21,\n",
       " 'carri': 120,\n",
       " 'tag': 36,\n",
       " 'becom': 327,\n",
       " 'cost': 358,\n",
       " 'long': 276,\n",
       " 'focu': 139,\n",
       " 'spur': 84,\n",
       " 'celtic': 63,\n",
       " 'toni': 71,\n",
       " 'score': 437,\n",
       " 'seasonhigh': 26,\n",
       " 'antonio': 49,\n",
       " 'seri': 399,\n",
       " 'boston': 291,\n",
       " 'post': 399,\n",
       " 'aol': 89,\n",
       " 'spam': 95,\n",
       " 'america': 320,\n",
       " 'provid': 493,\n",
       " 'signific': 76,\n",
       " 'amount': 62,\n",
       " 'sent': 105,\n",
       " 'subscrib': 51,\n",
       " 'five': 304,\n",
       " 'complain': 23,\n",
       " 'abc': 100,\n",
       " 'quarterback': 186,\n",
       " 'john': 348,\n",
       " 'david': 209,\n",
       " 'pass': 146,\n",
       " 'ball': 101,\n",
       " 'half': 255,\n",
       " 'colleg': 191,\n",
       " 'footbal': 356,\n",
       " 'threw': 59,\n",
       " 'touchdown': 126,\n",
       " 'formal': 34,\n",
       " 'suffer': 118,\n",
       " 'attack': 327,\n",
       " 'believ': 113,\n",
       " 'hospit': 154,\n",
       " 'doctor': 74,\n",
       " 'singer': 162,\n",
       " 'follow': 309,\n",
       " 'ceremoni': 58,\n",
       " 'confer': 263,\n",
       " 'aug': 131,\n",
       " 'photo': 476,\n",
       " 'name': 373,\n",
       " 'among': 207,\n",
       " 'least': 235,\n",
       " 'appear': 232,\n",
       " 'headlin': 41,\n",
       " 'recent': 296,\n",
       " 'album': 98,\n",
       " 'usual': 55,\n",
       " 'stay': 162,\n",
       " 'behind': 189,\n",
       " 'pen': 27,\n",
       " 'artist': 97,\n",
       " 'kelli': 28,\n",
       " 'piston': 72,\n",
       " 'jame': 179,\n",
       " 'cavali': 54,\n",
       " 'smart': 65,\n",
       " 'philippin': 30,\n",
       " 'auburn': 40,\n",
       " 'hill': 119,\n",
       " 'michigan': 63,\n",
       " 'basketbal': 206,\n",
       " 'associ': 279,\n",
       " 'champion': 294,\n",
       " 'detroit': 164,\n",
       " 'lebron': 39,\n",
       " 'munich': 20,\n",
       " 'set': 648,\n",
       " 'linux': 188,\n",
       " 'despit': 237,\n",
       " 'patent': 122,\n",
       " 'worri': 159,\n",
       " 'declar': 72,\n",
       " 'abandon': 46,\n",
       " 'microsoft': 899,\n",
       " 'favor': 42,\n",
       " 'ahead': 263,\n",
       " 'scientist': 198,\n",
       " 'pictur': 135,\n",
       " 'saturn': 37,\n",
       " 'mysteri': 58,\n",
       " 'moon': 90,\n",
       " 'nasa': 216,\n",
       " 'cassini': 22,\n",
       " 'spacecraft': 64,\n",
       " 'thick': 22,\n",
       " 'mile': 65,\n",
       " 'titan': 80,\n",
       " 'bond': 166,\n",
       " 'weak': 92,\n",
       " 'job': 447,\n",
       " 'barrel': 130,\n",
       " 'septemb': 160,\n",
       " 'touch': 57,\n",
       " 'econom': 230,\n",
       " 'indic': 68,\n",
       " 'wide': 90,\n",
       " 'futur': 323,\n",
       " 'edg': 106,\n",
       " 'suggest': 117,\n",
       " 'slow': 152,\n",
       " 'privat': 181,\n",
       " 'enterpris': 163,\n",
       " 'revenu': 196,\n",
       " 'portfolio': 36,\n",
       " 'health': 240,\n",
       " 'care': 101,\n",
       " 'biotech': 22,\n",
       " 'semiconductor': 53,\n",
       " 'unveil': 170,\n",
       " 'remark': 28,\n",
       " 'similar': 61,\n",
       " 'sec': 61,\n",
       " 'advis': 27,\n",
       " 'fanni': 26,\n",
       " 'mae': 33,\n",
       " 'restat': 24,\n",
       " 'stake': 176,\n",
       " 'commiss': 183,\n",
       " 'dump': 31,\n",
       " 'ranger': 74,\n",
       " 'europ': 230,\n",
       " 'striker': 37,\n",
       " ...}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of Words Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = []\n",
    "for k, v in list(final_dict.items()):\n",
    "    bag_of_words.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3664"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = np.array(bag_of_words)\n",
    "bag_of_words = np.unique(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_bag = dict()\n",
    "for i in range(len(bag_of_words)):\n",
    "    final_bag[bag_of_words[i]] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving bag of words as array object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constructing the feature matrix and class labels vector\n",
    "labels = list(set(df['category']))\n",
    "labels = sorted(labels)\n",
    "\n",
    "rows = len(df)\n",
    "columns = len(final_bag)\n",
    "\n",
    "with open('D:/NLP Project/Data/bag_of_words.npy', 'wb') as f:\n",
    "    np.save(f,bag_of_words,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing Feature matrix/Term document matrix of the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = np.full((rows,columns),0)\n",
    "class_labels   = np.full((rows),0)\n",
    "\n",
    "for i in range(len(df)):\n",
    "    ind_i = df['url'][i]\n",
    "    #print(\"Document Index :\"+str(ind_i))\n",
    "    label =  labels.index(df['category'][i])\n",
    "    class_labels [ind_i] = label\n",
    "    #cnt = 0\n",
    "    for j in range(len(df['doc'][i])):\n",
    "        if df['doc'][i][j] in final_dict.keys(): ## To avoid Key Error in Dictionary.\n",
    "            ind_j = final_bag[df['doc'][i][j]]\n",
    "            feature_matrix[ind_i][ind_j]=1\n",
    "            #cnt += 1\n",
    "    #print(str(cnt)+ \" updations for this article\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove documents with all 0's in row from feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943\n"
     ]
    }
   ],
   "source": [
    "indices_to_remove = np.argwhere(np.all(feature_matrix == 0, axis=1))\n",
    "print(len(indices_to_remove))\n",
    "indices_to_remove = indices_to_remove.tolist()\n",
    "indices_to_remove = [item for sublist in indices_to_remove for item in sublist]\n",
    "#feature_matrix = np.delete(feature_matrix,indices_to_remove) # Feature matrix is reshaping while deleting, so using dataframes below and converting back to array.\n",
    "class_labels = np.delete(class_labels,indices_to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert matrix to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_df = ps.DataFrame(feature_matrix)\n",
    "a_series = (feat_df != 0).any(axis=1)\n",
    "new_feat = feat_df.loc[a_series]\n",
    "feat_df = new_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_in_doc = dict()\n",
    "for i in range(len(feat_df.columns)):\n",
    "    row_indices = np.where(feat_df[i]==1)\n",
    "    word_in_doc[feat_df.columns[i]] = row_indices # word 0 : [1,25,30]\n",
    "    tupl = word_in_doc[i]\n",
    "    listt = list(tupl)\n",
    "    row_indices = listt[0].tolist()\n",
    "    word_in_doc[feat_df.columns[i]] = row_indices\n",
    "    #print(word_in_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = new_feat.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding documents with words common among them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in word_in_doc.items():\n",
    "    word_in_doc[k] = list(itertools.combinations(v, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3664"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_in_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tpls = []\n",
    "for k,v in word_in_doc.items():\n",
    "    all_tpls.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_tuples = [item for sublist in all_tpls for item in sublist] # Converting list of list to flat list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69277103"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flat_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_tuples = Counter(flat_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_tuple = dict(cnt_tuples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Dataframe with URL Tuple and edge weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_edge_list = ps.DataFrame(cnt_tuples.items(),columns = ['url_tuple','edge_weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expanding tuples into 2 columns (For source and destination nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_col_list = ['url1','url2']\n",
    "for n,col in enumerate(new_col_list):\n",
    "    weighted_edge_list[col] = weighted_edge_list['url_tuple'].apply(lambda url_tuple: url_tuple[n])\n",
    "\n",
    "weighted_edge_list = weighted_edge_list.drop('url_tuple',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edge_weight</th>\n",
       "      <th>url1</th>\n",
       "      <th>url2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>5361</td>\n",
       "      <td>5362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>5361</td>\n",
       "      <td>5363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>5361</td>\n",
       "      <td>5364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>5361</td>\n",
       "      <td>5365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>5361</td>\n",
       "      <td>5366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   edge_weight  url1  url2\n",
       "0            7  5361  5362\n",
       "1            8  5361  5363\n",
       "2            7  5361  5364\n",
       "3            6  5361  5365\n",
       "4            6  5361  5366"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_edge_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url1</th>\n",
       "      <th>url2</th>\n",
       "      <th>edge_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5361</td>\n",
       "      <td>5362</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5361</td>\n",
       "      <td>5363</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5361</td>\n",
       "      <td>5364</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5361</td>\n",
       "      <td>5365</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5361</td>\n",
       "      <td>5366</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   url1  url2  edge_weight\n",
       "0  5361  5362            7\n",
       "1  5361  5363            8\n",
       "2  5361  5364            7\n",
       "3  5361  5365            6\n",
       "4  5361  5366            6"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['url1','url2','edge_weight']\n",
    "weighted_edge_list = weighted_edge_list[cols]\n",
    "weighted_edge_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45259074"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weighted_edge_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the dataframe of edges and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_edge_list.to_csv(\"D:/NLP Project/Data/edge_list.csv\",index=None,line_terminator=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the feature matrix and class labels as numpy array object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving feature matrix and class labels to numpy files\n",
    "with open('D:/NLP Project/Data/feature_matrix.npy', 'wb') as f:\n",
    "    np.save(f,feature_matrix,allow_pickle=True)\n",
    "with open('D:/NLP Project/Data/class_lables.npy', 'wb') as f:\n",
    "    np.save(f,class_labels,allow_pickle=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5179d32cf6ec497baf3f8a3ef987cc77c5d2dc691fdde20a56316522f61a7323"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
